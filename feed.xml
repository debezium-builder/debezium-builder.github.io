<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://debezium.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://debezium.io/" rel="alternate" type="text/html" /><updated>2021-06-22T23:43:34+00:00</updated><id>https://debezium.io/feed.xml</id><title type="html">Debezium</title><subtitle>Debezium is an open source distributed platform for change data capture. Start it up, point it at your databases, and your apps can start responding to all of the inserts, updates, and deletes that other apps commit to your databases. Debezium is durable and fast, so your apps can respond quickly and never miss an event, even when things go wrong.</subtitle><entry><title type="html">Debezium 1.6.0.Beta2 Released</title><link href="https://debezium.io/blog/2021/06/10/debezium-1-6-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.Beta2 Released" /><published>2021-06-10T00:00:00+00:00</published><updated>2021-06-10T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/06/10/debezium-1-6-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/06/10/debezium-1-6-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.6.0.Beta2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release adds support for Pravega to Debezium Server, expands the snapshotting options of the Debezium Oracle connector,
and provides a range of bug fixes and other improvements across different Debezium connectors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;pravega_support_for_debezium_server&quot;&gt;Pravega Support for Debezium Server&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With &lt;a href=&quot;/documentation/reference/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt;,
we&amp;#8217;re on a mission to bring open-source change data capture to all the users,
no matter which data streaming platform or commit log they are using.
So we are very happy to receive a contribution which adds support for &lt;a href=&quot;https://pravega.io/&quot;&gt;Pravega&lt;/a&gt; to Debezium Server.
A Cloud Native Computing Foundation (CNCF) sandbox and Apache 2.0 licensed open-source project,
Pravega describes itself as a &quot;storage abstraction for continuously generated and unbounded data&quot;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium Server Pravega sink adapter offers two modes: non-transactional and transactional.
The non-transactional mode individually writes each event in a Debezium batch to Pravega.
The transactional mode writes the Debezium batch to a Pravega transaction that commits when the batch is completed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To learn more about using Debezium with Pravega, please refer to the &lt;a href=&quot;/documentation/reference/operations/debezium-server.html#_pravega&quot;&gt;documentation&lt;/a&gt;.
Many thanks to &lt;a href=&quot;https://twitter.com/derekm00r3&quot;&gt;Derek Moore&lt;/a&gt; for this fantastic contribution!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;oracle_snapshotting_improvements&quot;&gt;Oracle Snapshotting Improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium connector for Oracle received two improvements related to snapshotting:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Support for the &lt;code&gt;snapshot.include.collection.list&lt;/code&gt; option (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3062&quot;&gt;DBZ-3062&lt;/a&gt;); this allows to create an initial snapshot only for a subset of all those tables captured by the connector&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New option &lt;code&gt;snapshot.locking.mode&lt;/code&gt; which provides control over the locking behavior when the connector captures the schema of the tables (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3557&quot;&gt;DBZ-3557&lt;/a&gt;); in particular, this allows to disable locking completely, which is very useful if you can guarantee that no DDL changes are happening while the connector is taking the (schema) snapshot&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition, there&amp;#8217;s several bug fixes for this connector, including a few ones related to DDL and DML parsing
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3545&quot;&gt;DBZ-3545&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3549&quot;&gt;DBZ-3549&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3554&quot;&gt;DBZ-3554&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3606&quot;&gt;DBZ-3606&lt;/a&gt;), handling of RAC installations (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3563&quot;&gt;DBZ-3563&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3599&quot;&gt;DBZ-3599&lt;/a&gt;),
and more efficient handling of LOB columns (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3556&quot;&gt;DBZ-3556&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;further_improvements_and_bugfixes&quot;&gt;Further Improvements and Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium connector for SQL Server saw two performance-related improvments
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3486&quot;&gt;3486&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3515&quot;&gt;DBZ-3515&lt;/a&gt;).
The schemas of change events from the Postgres connector contain default values now, based on the source column definition
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2790&quot;&gt;DBZ-2790&lt;/a&gt;).
This comes in handy for instance when deriving downstream table schemas from a change event stream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Other fixes include correct identification of primary members in MongoDB replica sets (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3522&quot;&gt;DBZ-3522&lt;/a&gt;),
support for the &lt;code&gt;JSON&lt;/code&gt; function in the MySQL connector&amp;#8217;s DDL parser (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3559&quot;&gt;DBZ-3559&lt;/a&gt;),
and the upgrade of the &lt;a href=&quot;/documentation/reference/integrations/outbox.html&quot;&gt;Debezium Quarkus extension&lt;/a&gt; for implementing the outbox pattern to Quarkus 2.0 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3550&quot;&gt;DBZ-3550&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-400?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.6.0.Beta2%20ORDER%20BY%20key%20ASC%2C%20component%20ASC&quot;&gt;48 issues&lt;/a&gt; have been addressed in Debezium 1.6.0.Beta2.
We&amp;#8217;re deeply grateful to all the community members contributing to this release:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Bob Roldan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ccollingwood&quot;&gt;Chris Collingwood&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Naros&quot;&gt;Chris Cranford&lt;/a&gt;,
&lt;a href=&quot;https://github.com/derekm&quot;&gt;Derek Moore&lt;/a&gt;,
&lt;a href=&quot;https://github.com/eslep&quot;&gt;Eric Slep&lt;/a&gt;,
&lt;a href=&quot;https://github.com/gvaquez-ubi&quot;&gt;Gilles Vaquez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/gunnarmorling&quot;&gt;Gunnar Morling&lt;/a&gt;,
Jackey Zhang,
&lt;a href=&quot;https://github.com/jcechace&quot;&gt;Jakub Cechacek&lt;/a&gt;,
&lt;a href=&quot;https://github.com/novotnyJiri&quot;&gt;Jiri Novotny&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jpechane&quot;&gt;Jiri Pechanec&lt;/a&gt;,
&lt;a href=&quot;https://github.com/kppullin&quot;&gt;Kevin Pullin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/roldanbob&quot;&gt;Robert Roldan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/sarafonseca-123&quot;&gt;Sara Fonseca&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With Beta2 through the door, we&amp;#8217;re entering the stabilization phase for the 1.6 release cycle.
You can expect one or two CRs (candidate releases),
before the final release, which is planned for the end of the month,
barring any unforeseen complications of cause.
Besides some more bug fixes and documentation improvements we&amp;#8217;re also intending to upgrade to Apache Kafka 2.8,
which will allow you to take a sneak peak at using Debezium with &lt;a href=&quot;https://www.morling.dev/blog/exploring-zookeeper-less-kafka/&quot;&gt;ZooKeeper-less Kafka&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In parallel, we&amp;#8217;re going to work on the roadmap for Debezium 1.7 (due by the end of September).
Please get in touch via the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; if you have specific feature requests for this release!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="outbox" /><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.6.0.Beta2! This release adds support for Pravega to Debezium Server, expands the snapshotting options of the Debezium Oracle connector, and provides a range of bug fixes and other improvements across different Debezium connectors.</summary></entry><entry><title type="html">Debezium 1.5.2.Final Released</title><link href="https://debezium.io/blog/2021/05/28/debezium-1-5-2-final-released/" rel="alternate" type="text/html" title="Debezium 1.5.2.Final Released" /><published>2021-05-28T00:00:00+00:00</published><updated>2021-05-28T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/28/debezium-1-5-2-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/28/debezium-1-5-2-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let me announce the bugfix release of Debezium 1.5, &lt;strong&gt;1.5.2.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release is a rebuild of 1.5.1.Final using Java 8.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium 1.5.1.Final was incorrectly built using Java 11.
That would prevent it running in environments still using Java 8.
This version is rebuilt using Java 8.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20and%20fixVersion%20%3D%201.5.2.Final&quot;&gt;2 issues&lt;/a&gt; were fixed for this release.
Thanks a lot to all contributors!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">Let me announce the bugfix release of Debezium 1.5, 1.5.2.Final! This release is a rebuild of 1.5.1.Final using Java 8.</summary></entry><entry><title type="html">Debezium 1.5.1.Final Released</title><link href="https://debezium.io/blog/2021/05/27/debezium-1-5-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.5.1.Final Released" /><published>2021-05-27T00:00:00+00:00</published><updated>2021-05-27T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/27/debezium-1-5-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/27/debezium-1-5-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let me announce the bugfix release of Debezium 1.5, &lt;strong&gt;1.5.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release fixes a small set of issues discovered since the original release and few improvements into the documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The two most important fixes in this release are related to the MySQL database history that can get potentially corrupted under an unfavorable set of conditions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you execute a &lt;code&gt;DROP TABLE&lt;/code&gt; command and the affected table&amp;#8217;s name contains dashes, then the resulting statement cannot be parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3485&quot;&gt;DBZ-3485&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;RENAME TABLE&lt;/code&gt; statements that contains more than one table can be stored incompletely (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3399&quot;&gt;DBZ-3399&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Both issues were introduced during the rewrite of MySQL connector and were not covered by integration tests.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We strongly recommend upgrading to 1.5.1.Final before you hit these issues.
If you are already affected, then the easiest way to recover from the error situation is using a new topic (or dropping the old one) for the database history and execute a &lt;code&gt;schema_only_recovery&lt;/code&gt; snapshot.
We apologize for the potential inconvenience.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3549?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.1.Final&quot;&gt;31 issues&lt;/a&gt; were fixed for this release.
Thanks a lot to all contributors!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">Let me announce the bugfix release of Debezium 1.5, 1.5.1.Final! This release fixes a small set of issues discovered since the original release and few improvements into the documentation.</summary></entry><entry><title type="html">Debezium 1.6.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/05/20/debezium-1-6-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.Beta1 Released" /><published>2021-05-20T00:00:00+00:00</published><updated>2021-05-20T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/20/debezium-1-6-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/20/debezium-1-6-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.6.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release introduces incremental snapshot support for SQL Server and Db2, performance improvements for SQL Server,
support for BLOB/CLOB for Oracle, and much more.  Lets take a few moments and explore some of these new features in the following.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;incremental_snapshotting_sql_server_db2&quot;&gt;Incremental Snapshotting - SQL Server / Db2&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium first introduced incremental snapshotting in 1.6.0.Alpha1.
As discussed in this &lt;a href=&quot;https://debezium.io/blog/2021/05/06/debezium-1-6-alpha1-released/&quot;&gt;blog post&lt;/a&gt;, there are several pain points that exist when running Debezium:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the necessity to execute consistent snapshots before streaming has begun upon connector restarts&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;inability to trigger full or even partial snapshots after having the connector running for extended periods of time&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With this release, this feature has been extended to both the SQL Server and Db2 connectors.
We intend to continue to roll this feature out to additional connectors in future releases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you would like to try the feature yourself then you need to&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;provide a &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/configuration/signalling.html#_overview&quot;&gt;signalling table&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;trigger an ad-hoc incremental snapshot by using a SQL command like&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;INSERT INTO myschema.debezium_signal VALUES('ad-hoc-1', 'execute-snapshot', '{&quot;data-collections&quot;: [&quot;schema1.table1&quot;, &quot;schema1.table2&quot;]}')&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;sql_server_performance_improvement&quot;&gt;SQL Server Performance Improvement&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The SQL Server connector option, &lt;code&gt;source.timestamp.mode&lt;/code&gt;, controls how the timestamp for an emitted event is resolved.
The default &lt;code&gt;commit&lt;/code&gt; setting is designed to resolve the timestamp based on when the change record was committed in the database.
It was identified that this method used separate JDBC calls to resolve the timestamp for an event, which caused a loss in both performance and throughput.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release fixes the &lt;code&gt;commit&lt;/code&gt; mode performance problem by moving where the timestamp is resolved.
This substantially increases the connector&amp;#8217;s performance and throughput while maintaining existing functionality.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We would like to thank &lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt; for identifying and contributing a solution to this problem.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;oracle_large_object_data_types&quot;&gt;Oracle Large Object Data Types&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the era of &quot;Big Data&quot;, its not all that uncommon to use data types such as &lt;code&gt;BLOB&lt;/code&gt; and &lt;code&gt;CLOB&lt;/code&gt; to store large object data.
The Debezium Oracle connector has supported a wide range of data types and we&amp;#8217;re happy to report that we&amp;#8217;ve now extended that support to cover large both BLOB and CLOB for both the XStream and LogMiner based implementations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When emitting events that contain &lt;code&gt;BLOB&lt;/code&gt; or &lt;code&gt;CLOB&lt;/code&gt; data, the memory footprint of the connector as well as the emitted event&amp;#8217;s message size will be directly impacted by the size of the large object data.
As a result, the connector&amp;#8217;s JVM process may require additional memory as well as adjusting some Kafka configurations, such as &lt;code&gt;message.max.bytes&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We encourage the community to test drive the support for these new data types and report any and all feedback.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Further fixes and improvements in this release include the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Debezium connector for Oracle now supports &lt;code&gt;ALTER TABLE&lt;/code&gt; and &lt;code&gt;DROP TABLE&lt;/code&gt; automatically (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2916&quot;&gt;DBZ-2916&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium connector for Oracle is tested and validated using ojdbc.jar version 21.1.0.0 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3460&quot;&gt;DBZ-3460&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium connector for MonogDB could lead to lost change events where a long running snapshot was greater than the configured oplog window (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3331&quot;&gt;DBZ-3331&lt;/a&gt;);
the connector now validates the oplog position&amp;#8217;s existance when streaming starts&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium connector for Cassandra was not responding to schema changes correctly (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3417&quot;&gt;DBZ-3417&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, a total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.6.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;52 issues&lt;/a&gt; have been addressed for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, a big thank you to all the community members who contributed:
&lt;a href=&quot;https://github.com/Alfusainey&quot;&gt;Alfusainey Jallow&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/CaoManhDat&quot;&gt;Cao Manh Dat&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/shiawu&quot;&gt;John Wu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/truman303&quot;&gt;Mike&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ojacquemart&quot;&gt;Olivier Jacquemart&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/siufay325&quot;&gt;SiuFay&lt;/a&gt;,
&lt;a href=&quot;https://github.com/smiklosovic&quot;&gt;Stefan Miklosovic&lt;/a&gt;,
&lt;a href=&quot;https://github.com/TAregger&quot;&gt;Thomas Aregger&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.6.0.Beta1! This release introduces incremental snapshot support for SQL Server and Db2, performance improvements for SQL Server, support for BLOB/CLOB for Oracle, and much more. Lets take a few moments and explore some of these new features in the following.</summary></entry><entry><title type="html">Debezium 1.6.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/05/06/debezium-1-6-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.6.0.Alpha1 Released" /><published>2021-05-06T00:00:00+00:00</published><updated>2021-05-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/05/06/debezium-1-6-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/05/06/debezium-1-6-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.6 series, &lt;strong&gt;1.6.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release brings the brand new feature called incremental snapshots for MySQL and PostgreSQL connectors,
a Kafka sink for Debezium Server,
as well as a wide range of bug fixes and other small feature additions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;incremental_snapshotting&quot;&gt;Incremental Snapshotting&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Running Debezium exhibits few pain-points&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the necessity to execute consistent snapshot before streaming is started upon new connector restart&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;inability to trigger full or partial snapshot after having connector to be running for some time&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Starting this release we are deploying the solution to both these potential pitfalls.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The simpler one - an ability to trigger the snapshot during the runtime is solved by &lt;strong&gt;ad-hoc snapshots&lt;/strong&gt;.
The user can trigger a snapshot anytime during the streaming phase by sending an &lt;code&gt;execute-snapshot&lt;/code&gt; &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/configuration/signalling.html&quot;&gt;signal&lt;/a&gt; to Debezium with the list of tables to be snapshotted and the type of the snapshot to be used (only &lt;code&gt;incremental&lt;/code&gt; is supported right now, see below).
When Debezium receives the signal it will execute the snapshot of the requested tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The more complex part that goes hand-in-hand with ad-hoc snapshotting is &lt;strong&gt;incremental snapshots&lt;/strong&gt;.
This feature allows the user to execute a snapshot of a set of tables during the streaming phase without interrupting the streaming.
Moreover, contrary to the initial snapshot, the snapshot will resume upon connector restart and does not need to start from scratch again.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The implementation of this feature is based on a novel approach to snapshotting originally invented by &lt;a href=&quot;https://arxiv.org/pdf/2010.12597v1.pdf&quot;&gt;DBLog Framework&lt;/a&gt;.
Debezium implementation is described in more detail in the &lt;a href=&quot;https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md&quot;&gt;design document&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you want to try the feature yourself then you need to&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;provide a &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/configuration/signalling.html#_overview&quot;&gt;signalling table&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;trigger an ad-hoc incremental snapshot by using SQL command like&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;INSERT INTO myschema.debezium_signal VALUES('ad-hoc-1', 'execute-snapshot', '{&quot;data-collections&quot;: [&quot;schema1.table1&quot;, &quot;schema1.table2&quot;]}')&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;kafka_sink_for_debezium_server&quot;&gt;Kafka Sink for Debezium Server&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium connectors can either run in Kafka Connect or can be deployed using &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt; that provides different destination sinks.
Starting with this release if a sink is Apache Kafka it is no longer necessary to use Kafka Connect but Debezium Server with &lt;a href=&quot;https://debezium.io/documentation/reference/1.6/operations/debezium-server.html#_apache_kafka&quot;&gt;Apache Kafka Sink&lt;/a&gt; could be used instead which may simplify operational requirements for some deployments.
In this case, the regular Apache Kafka client API is used.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether,  &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;47 issues&lt;/a&gt; were fixed for this release.
A big thank you goes out to all the community members who contributed:
&lt;a href=&quot;https://github.com/Alfusainey&quot;&gt;Alfusainey Jallow&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/blcksrx&quot;&gt;Hossein Torabi&lt;/a&gt;,
&lt;a href=&quot;https://github.com/kyleyj&quot;&gt;Kyley Jex&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/patrichu-cisco&quot;&gt;Patrick Chu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/raphaelauv&quot;&gt;Raphael Auv&lt;/a&gt;,
&lt;a href=&quot;https://github.com/tommyk-gears&quot;&gt;Tommy Karlsson&lt;/a&gt;,
&lt;a href=&quot;https://github.com/elgca&quot;&gt;WenChao Ke&lt;/a&gt;,
and &lt;a href=&quot;https://github.com/jjiey&quot;&gt;yangsanity&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For the upcoming 1.6 preview releases, we&amp;#8217;re planning to focus on completing the follow-up task for incremental snapshotting and provide the support for SQL Server and Db2 connectors too, further improving the LogMiner-based connector implementation for Oracle mainly related to schema evolutions and LOB support.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.6 series, 1.6.0.Alpha1! This release brings the brand new feature called incremental snapshots for MySQL and PostgreSQL connectors, a Kafka sink for Debezium Server, as well as a wide range of bug fixes and other small feature additions.</summary></entry><entry><title type="html">Debezium 1.5.0.Final Released</title><link href="https://debezium.io/blog/2021/04/08/debezium-1-5-final-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Final Released" /><published>2021-04-08T00:00:00+00:00</published><updated>2021-04-08T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/04/08/debezium-1-5-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/04/08/debezium-1-5-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m thrilled to announce the release of Debezium &lt;strong&gt;1.5.0.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With Debezium 1.5, the LogMiner-based &lt;a href=&quot;/documentation/reference/1.5/connectors/oracle.html&quot;&gt;CDC implementation for Oracle&lt;/a&gt; moves from Incubating to Stable state,
and there&amp;#8217;s a brand-new implementation of the MySQL connector,
which brings features like &lt;a href=&quot;/documentation/reference/1.5/connectors/mysql.html#mysql-transaction-metadata&quot;&gt;transaction metadata support&lt;/a&gt;.
Other key features include support for a new &quot;signalling table&quot;, which for instance can be used to implement &lt;a href=&quot;/documentation/reference/1.5/connectors/oracle.html#surrogate-schema-evolution&quot;&gt;schema changes&lt;/a&gt; with the Oracle connector,
and support for &lt;code&gt;TRUNCATE&lt;/code&gt; events with Postgres.
There&amp;#8217;s also many improvements to the community-led connectors for &lt;a href=&quot;/documentation/reference/1.5/connectors/vitess.html&quot;&gt;Vitess&lt;/a&gt; and &lt;a href=&quot;/documentation/reference/1.5/connectors/cassandra.html&quot;&gt;Apache Cassandra&lt;/a&gt;,
as well as wide range of bug fixes and other smaller improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Across all the 1.5 preview and the final releases, a grand total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.5.0.Alpha1%2C%201.5.0.Beta1%2C%201.5.0.Beta2%2C%201.5.0.CR1%2C%201.5.0.Final)&quot;&gt;236 issues&lt;/a&gt; has been addressed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For more details, please see the earlier announcements for the &lt;a href=&quot;/blog/2021/02/08/debezium-1-5-alpha1-released/&quot;&gt;1.5.0 Alpha1&lt;/a&gt;,
&lt;a href=&quot;/blog/2021/02/24/debezium-1-5-beta1-released/&quot;&gt;Beta1&lt;/a&gt;,
&lt;a href=&quot;/blog/2021/03/15/debezium-1-5-beta2-released/&quot;&gt;Beta2&lt;/a&gt;,
and &lt;a href=&quot;/blog/2021/03/24/debezium-1-5-cr1-released/&quot;&gt;CR1&lt;/a&gt; releases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since the CR1 release, we&amp;#8217;ve primarily focused on documentation improvements and some bug fixes.
But there are two last-minute feature additions, too:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;/documentation/reference/1.5/operations/debezium-server.html#_redis_stream&quot;&gt;Support for Redis Streams&lt;/a&gt; in Debezium Server (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2879&quot;&gt;DBZ-2879&lt;/a&gt;),
allowing to propagate Debezium data change events into &lt;a href=&quot;https://redis.io/topics/streams-intro&quot;&gt;Redis-based logs&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide LSN coordinates as standardized sequence field in Postgres change events (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2911&quot;&gt;DBZ-2911&lt;/a&gt;),
allowing consumers to identify duplicated events and exclude them from processing, for instance after an un-clean connector shut-down; this field will be added to the &lt;code&gt;source&lt;/code&gt; block of other connectors going forward, too&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to the &lt;a href=&quot;/releases/1.5/release-notes#release-1.5.0-final&quot;&gt;release notes&lt;/a&gt; of Debezium 1.5.0.Final for the complete list of resolved issues as well as procedures for upgrading to earlier versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, a big thank you to all the members from the community who helped with this release,
be it via code contributions, bug report, testing, providing insight and expertise, etc.
In particular for the LogMiner-based CDC implementation for Oracle, we&amp;#8217;ve received a huge number of contributions of all kinds.
We&amp;#8217;re deeply grateful for that and look forward a lot to further grow and improve this connector implementation!
Kudos to the following individuals from the community which contributed to Debezium 1.5, bringing the &lt;a href=&quot;https://github.com/debezium/debezium/graphs/contributors&quot;&gt;overall number&lt;/a&gt; of contributors to the Debezium core repository to 253:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/adhaamehab&quot;&gt;Adhaam Ehab&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/davecramer&quot;&gt;Dave Cramer&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ddseapy&quot;&gt;David Seapy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/fahimfarookme&quot;&gt;Fahim Farook&lt;/a&gt;,
&lt;a href=&quot;https://github.com/frankkoornstra&quot;&gt;Frank Koornstra&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/JeremyVigny&quot;&gt;Jeremy Vigny&lt;/a&gt;.
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/kppullin&quot;&gt;Kevin Pullin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/msillence&quot;&gt;Martin Sillence&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mengqiu&quot;&gt;Meng Qiu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelcizmar&quot;&gt;Michael Cizmar&lt;/a&gt;,
&lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt;,
&lt;a href=&quot;https://github.com/pkpfr&quot;&gt;Nick Murray&lt;/a&gt;,
&lt;a href=&quot;https://github.com/nitin456&quot;&gt;Nitin Agarwal&lt;/a&gt;,
&lt;a href=&quot;https://github.com/r-ballard&quot;&gt;Russell Ballard&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mrshanepaul&quot;&gt;Shane Paul&lt;/a&gt;,
&lt;a href=&quot;https://github.com/tprelle&quot;&gt;Thomas Prelle&lt;/a&gt;,
&lt;a href=&quot;https://github.com/twthorn&quot;&gt;Thomas Thornton&lt;/a&gt;,
&lt;a href=&quot;https://github.com/denisprog&quot;&gt;Victar Malinouski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vaosinbi&quot;&gt;Vladimir Osin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Cyril-Engels&quot;&gt;Yilong Chang&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Following our quarterly release cadence, Debezium 1.6 is planned for the end of June.
A key issue we&amp;#8217;re planning to work on for this version is explorations of how to improve the notion of initial snapshots,
where we plan to touch on topics like resumeability, parallelization, changes of filter configuration, and more.
This is going to be an open-ended investigation, but we hope to have at least a proof-of-concept implementation for some of these features,
which constantly show up high on the wish list of Debezium users.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another focus area will again be the Debezium connector for Oracle, where we have planned several functional and performance improvements.
We are also discussing to move to Java 11 as a minimum baseline for running Debezium.
This is primarily caused by external dependencies which are moving on from Java 8.
In case you have specific questions or potential concerns around this change, please chime into &lt;a href=&quot;https://groups.google.com/g/debezium/c/ZVOYm_S3Jk4&quot;&gt;the discussion&lt;/a&gt;.
Also, if you got specific feature requests or other input for the roadmap and future releases, please let us know via the &lt;a href=&quot;https://groups.google.com/g/debezium&quot;&gt;mailing list&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I&amp;#8217;m thrilled to announce the release of Debezium 1.5.0.Final! With Debezium 1.5, the LogMiner-based CDC implementation for Oracle moves from Incubating to Stable state, and there&amp;#8217;s a brand-new implementation of the MySQL connector, which brings features like transaction metadata support. Other key features include support for a new &quot;signalling table&quot;, which for instance can be used to implement schema changes with the Oracle connector, and support for TRUNCATE events with Postgres. There&amp;#8217;s also many improvements to the community-led connectors for Vitess and Apache Cassandra, as well as wide range of bug fixes and other smaller improvements.</summary></entry><entry><title type="html">Debezium 1.5.0.CR1 Released</title><link href="https://debezium.io/blog/2021/03/24/debezium-1-5-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.CR1 Released" /><published>2021-03-24T00:00:00+00:00</published><updated>2021-03-24T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/03/24/debezium-1-5-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/03/24/debezium-1-5-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the release of Debezium &lt;strong&gt;1.5.0.CR1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As we begin moving toward finalizing the Debezium 1.5 release stream,
the Oracle connector has been promoted to stable and there were some TLS improvements for the Cassandra connector, as well as numerous bugfixes.
Overall, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.CR1%20ORDER%20BY%20issuetype%20DESC&amp;amp;startIndex=20&quot;&gt;50 issues&lt;/a&gt; have been addressed for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;oracle_connector_now_stable&quot;&gt;Oracle connector now stable&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Oracle connector has been in incubating status for a while but recent efforts have helped to bring new features and stability to the connector.
We felt at this point, the connector is ready so with this release we&amp;#8217;re officially promoting the Oracle connector from &lt;em&gt;incubating&lt;/em&gt; to &lt;strong&gt;stable&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A tremendous effort by the community has made all this possible.
The numerous contributions, bug reports, and testing has helped so much!
The team and I cannot thank the community enough for all its insight, help, and dedication in making this milestone a reality so quickly!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;cassandra_connector_tls_improvements&quot;&gt;Cassandra connector TLS improvements&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Cassandra connector uses the defaut available ciphers to establish SSL connections.
For most use cases, this is more than satisfactory; however it does prevent the use of non-standard ciphers.
In this release, the Cassandra connector property file can be configured to specify a list of ciphers in precedence order for use.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To use this new feature, add a line to the connector&amp;#8217;s property file like below:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;cipherSuites=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A number of bugs were fixed in this release, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Debezium logs &quot;is not a valid Avro schema name&quot; can be too verbose &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2511&quot;&gt;DBZ-2511&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;message.key.columns Regex Validation Time Complexity &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2957&quot;&gt;DBZ-2957&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OID values don&amp;#8217;t fit to INT32 schema &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3033&quot;&gt;DBZ-3033&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connector automatically restart on ORA-26653 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3236&quot;&gt;DBZ-3236&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;UI container has no assets (JS artifacts, fonts, etc) and randomly fails building &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3247&quot;&gt;DBZ-3247&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Revert Clob behavior for Oracle LogMiner to avoid null values &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3257&quot;&gt;DBZ-3257&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQL Server misses description for decimal.handling.mode &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3267&quot;&gt;DBZ-3267&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oracle connector ignores time.precision.mode and just uses adaptive mode &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3268&quot;&gt;DBZ-3268&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;commons-logging JAR is missing from Debezium Server distro &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3277&quot;&gt;DBZ-3277&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MongoDB timeouts crash the whole connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3278&quot;&gt;DBZ-3278&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prefer archive logs over redo logs of the same SCN range &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3292&quot;&gt;DBZ-3292&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LogMiner mining query may unintentionally skip records &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3295&quot;&gt;DBZ-3295&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IndexOutOfBoundsException when LogMiner DML update statement contains a function as last column&amp;#8217;s value &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3305&quot;&gt;DBZ-3305&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Out of memory with mysql snapshots (regression of DBZ-94 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3309&quot;&gt;DBZ-3309&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keyword ORDER is a valid identifier in MySQL grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3310&quot;&gt;DBZ-3310&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DDL statement couldn&amp;#8217;t be parsed for ROW_FORMAT=TOKUDB_QUICKLZ &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3311&quot;&gt;DBZ-3311&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LogMiner can miss a log switch event if too many switches occur. &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3319&quot;&gt;DBZ-3319&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Function MOD is missing from MySQL grammar &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3333&quot;&gt;DBZ-3333&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Incorrect SR label names in OCP testusite &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3336&quot;&gt;DBZ-3336&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DB2 upstream tests are still using master as the default branch &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-3337&quot;&gt;DBZ-3337&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, please refer to the &lt;a href=&quot;/releases/1.5/release-notes/#release-1.5.0-cr1&quot;&gt;release notes&lt;/a&gt; for the complete list of resolved issues as well as procedures for upgrading to earlier Debezium versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/frankkoornstra&quot;&gt;Frank Koornstra&lt;/a&gt; and
&lt;a href=&quot;https://github.com/JeremyVigny&quot;&gt;Jeremy Vigny&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As we begin to wrap up Debezium 1.5 and barring any unforeseen regressions or bug reports, we expect Debezium 1.5  Final to be released by the end of March.
Once 1.5 Final is out, we&amp;#8217;ll begin our focus toward 1.6.
We have quite a bit in store for Debezium 1.6 so stay tuned to learn what is lurking just around the corner!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">It&amp;#8217;s my pleasure to announce the release of Debezium 1.5.0.CR1! As we begin moving toward finalizing the Debezium 1.5 release stream, the Oracle connector has been promoted to stable and there were some TLS improvements for the Cassandra connector, as well as numerous bugfixes. Overall, 50 issues have been addressed for this release.</summary></entry><entry><title type="html">Understanding Non-Key Joins With the Quarkus Extension for Kafka Streams</title><link href="https://debezium.io/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams/" rel="alternate" type="text/html" title="Understanding Non-Key Joins With the Quarkus Extension for Kafka Streams" /><published>2021-03-18T00:00:00+00:00</published><updated>2021-03-18T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams</id><content type="html" xml:base="https://debezium.io/blog/2021/03/18/understanding-non-key-joins-with-quarkus-extension-for-kafka-streams/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation/streams/&quot;&gt;Kafka Streams&lt;/a&gt; is a library for developing stream processing applications based on Apache Kafka.
Quoting its docs, &quot;a Kafka Streams application processes record streams through a topology in real-time, processing data continuously, concurrently, and in a record-by-record manner&quot;.
The Kafka Streams DSL provides a range of stream processing operations such as a map, filter, join, and aggregate.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;non_key_joins_in_kafka_streams&quot;&gt;Non-Key Joins in Kafka Streams&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Debezium’s CDC source connectors make it easy to capture data changes in databases and push them towards sink systems such as Elasticsearch in near real-time.
By default, this results in a 1:1 relationship between tables in the source database, the corresponding Kafka topics,
and a representation of the data at the sink side, such as a search index in Elasticsearch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In case of 1:n relationships, say between a table of customers and a table of addresses,
consumers often are interested  in a view of the data that is a single, nested data structure, e.g. a single Elasticsearch document representing a customer and all their addresses.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is where &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-213+Support+non-key+joining+in+KTable&quot;&gt;KIP-213&lt;/a&gt; (&quot;Kafka Improvement Proposal&quot;) and its foreign key joining capabilities come in:
it was introduced in &lt;a href=&quot;https://kafka.apache.org&quot;&gt;Apache Kafka&lt;/a&gt; 2.4 &quot;to close the gap between the semantics of KTables in streams and tables in relational databases&quot;.
Before KIP-213, in order to join messages from two Debezium change event topics, you&amp;#8217;d typically have to manually re-key at least one of the topics, so to make sure the same key is used on both sides of the join.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thanks to KIP-213, this isn&amp;#8217;t needed any longer, as it allows to join two Kafka topics on fields extracted from the Kafka message value,
taking care of the required re-keying automatically, in a fully transparent way.
Comparing to &lt;a href=&quot;/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/&quot;&gt;previous approaches&lt;/a&gt;,
this drastically reduces the effort for creating aggregated events from Debezium’s CDC events.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Non-key joins or rather &lt;a href=&quot;https://kafka.apache.org/27/documentation/streams/developer-guide/dsl-api.html#ktable-ktable-fk-join&quot;&gt;foreign-key joins&lt;/a&gt; are analogous to joins in SQL such as the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; CUSTOMER &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; ADDRESS &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; CUSTOMER.ID = ADDRESS.CUSTOMER_ID&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In Kafka Streams terms, the output of such join is a new &lt;code&gt;KTable&lt;/code&gt; containing the join result.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;database_overview&quot;&gt;Database Overview&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Sticking to our earlier example of customers and address, let&amp;#8217;s consider an application with the following data model:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/kstreams_db_diagram.jpg&quot; class=&quot;responsive-image&quot; alt=&quot;Database Overview&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The two entities, customer and address, share a foreign key relationship from address to customer, i.e. a customer can have multiple addresses.
As stated above, by default Debezium will emit events for each table on distinct topics.
Using Kafka Streams, the change event topics for both tables will be loaded into two &lt;code&gt;KTable&lt;/code&gt;s, which are joined on the customer id.
The Kafka Streams application is going to process data from the two Kafka topics.
Whenever there&amp;#8217;s a new CDC event on either topic&amp;#8201;&amp;#8212;&amp;#8201;triggered by the insertion, update, or deletion of a record&amp;#8201;&amp;#8212;&amp;#8201;the join will be re-executed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As a runtime for the Kafka Streams application, we&amp;#8217;re going to use &lt;a href=&quot;https://quarkus.io/&quot;&gt;Quarkus&lt;/a&gt;, a stack for building cloud-native microservices, which (amongst many others) also provides an &lt;a href=&quot;https://quarkus.io/guides/kafka-streams&quot;&gt;extension&lt;/a&gt; for Kafka Streams. While it&amp;#8217;s general possible to run a Kafka Streams topology via a plain &lt;code&gt;main()&lt;/code&gt; method, using Quarkus and this extension as a foundation has a number of advantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Management of the topology (e.g. waiting for all input topics to be created)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configurability via environment variables, system properties etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exposing health checks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exposing metrics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Dev Mode&lt;/em&gt;, a way of working on the stream topology with automatic hot code replacement after code changes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for executing the Kafka Streams pipeline as a native binary via &lt;a href=&quot;https://www.graalvm.org/&quot;&gt;GraalVM&lt;/a&gt;, resulting in a signficantly reduced memory consumption and start-up times&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/kstreams_change_event_overview.png&quot; class=&quot;responsive-image&quot; alt=&quot;Change Event Overview&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This picture shows an overview of our solution.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;creating_an_application_using_the_quarkus_kafka_streams_extension&quot;&gt;Creating an Application using the Quarkus Kafka Streams Extension&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To create a new Quarkus project with the Kafka Streams extension, run the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;mvn io.quarkus:quarkus-maven-plugin:1.12.2.Final:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=customer-addresses-aggregator \
    -Dextensions=&quot;kafka-streams&quot;
cd customer-addresses-aggregator&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;understanding_the_stream_processing_topology&quot;&gt;Understanding the Stream Processing Topology&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We have an aggregator application that will read from the two Kafka topics and process them in a streaming pipeline:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the two topics are joined on customer id&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;each customer is enriched with its addresses&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;this aggregated data is written out to a third topic, &lt;code&gt;customersWithAddressesTopic&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When using the Quarkus extension for Kafka Streams, all we need to do for that is to declare a &lt;a href=&quot;http://www.cdi-spec.org/&quot;&gt;CDI producer method&lt;/a&gt;,
which returns the topology of our stream processing application.
This method must be annotated with &lt;code&gt;@Produces&lt;/code&gt;, and it must return a &lt;code&gt;Topology&lt;/code&gt; instance.
The Quarkus extension is responsible for configuring, starting, and stopping the Kafka Streams engine.
Now let&amp;#8217;s take a look at the actual streaming query implementation itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;&lt;span class=&quot;annotation&quot;&gt;@ApplicationScoped&lt;/span&gt;
&lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;TopologyProducer&lt;/span&gt; {

    &lt;span class=&quot;annotation&quot;&gt;@ConfigProperty&lt;/span&gt;(name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;) &lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;(1)&lt;/b&gt;
    &lt;span class=&quot;predefined-type&quot;&gt;String&lt;/span&gt; customersTopic;

    &lt;span class=&quot;annotation&quot;&gt;@ConfigProperty&lt;/span&gt;(name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;addresses.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;)
    &lt;span class=&quot;predefined-type&quot;&gt;String&lt;/span&gt; addressesTopic;

    &lt;span class=&quot;annotation&quot;&gt;@ConfigProperty&lt;/span&gt;(name = &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customers.with.addresses.topic&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;)
    &lt;span class=&quot;predefined-type&quot;&gt;String&lt;/span&gt; customersWithAddressesTopic;

    &lt;span class=&quot;annotation&quot;&gt;@Produces&lt;/span&gt;
    &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; Topology buildTopology() {
        StreamsBuilder builder = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; StreamsBuilder(); &lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;(2)&lt;/b&gt;

        Serde&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Long&lt;/span&gt;&amp;gt; adressKeySerde = DebeziumSerdes.payloadJson(&lt;span class=&quot;predefined-type&quot;&gt;Long&lt;/span&gt;.class);
        adressKeySerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.emptyMap(), &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;);
        Serde&amp;lt;Address&amp;gt; addressSerde = DebeziumSerdes.payloadJson(Address.class);
        addressSerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.singletonMap(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;from.field&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;), &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;);

        Serde&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;&amp;gt; customersKeySerde = DebeziumSerdes.payloadJson(&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;.class);
        customersKeySerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.emptyMap(), &lt;span class=&quot;predefined-constant&quot;&gt;true&lt;/span&gt;);
        Serde&amp;lt;Customer&amp;gt; customersSerde = DebeziumSerdes.payloadJson(Customer.class);
        customersSerde.configure(&lt;span class=&quot;predefined-type&quot;&gt;Collections&lt;/span&gt;.singletonMap(&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;from.field&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;after&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;), &lt;span class=&quot;predefined-constant&quot;&gt;false&lt;/span&gt;);

        JsonbSerde&amp;lt;AddressAndCustomer&amp;gt; addressAndCustomerSerde =
                &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; JsonbSerde&amp;lt;&amp;gt;(AddressAndCustomer.class); &lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;(3)&lt;/b&gt;
        JsonbSerde&amp;lt;CustomerWithAddresses&amp;gt; customerWithAddressesSerde =
                &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; JsonbSerde&amp;lt;&amp;gt;(CustomerWithAddresses.class);

        KTable&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Long&lt;/span&gt;, Address&amp;gt; addresses = builder.table( &lt;i class=&quot;conum&quot; data-value=&quot;4&quot;&gt;&lt;/i&gt;&lt;b&gt;(4)&lt;/b&gt;
                addressesTopic,
                Consumed.with(adressKeySerde, addressSerde)
        );

        KTable&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;, Customer&amp;gt; customers = builder.table(
                customersTopic,
                Consumed.with(customersKeySerde, customersSerde)
        );

        KTable&amp;lt;&lt;span class=&quot;predefined-type&quot;&gt;Integer&lt;/span&gt;, CustomerWithAddresses&amp;gt; customersWithAddresses = addresses.join( &lt;i class=&quot;conum&quot; data-value=&quot;5&quot;&gt;&lt;/i&gt;&lt;b&gt;(5)&lt;/b&gt;
                customers,
                address -&amp;gt; address.customer_id,
                AddressAndCustomer::&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt;,
                Materialized.with(Serdes.Long(), addressAndCustomerSerde)
            )
            .groupBy( &lt;i class=&quot;conum&quot; data-value=&quot;6&quot;&gt;&lt;/i&gt;&lt;b&gt;(6)&lt;/b&gt;
                (addressId, addressAndCustomer) -&amp;gt; KeyValue.pair(
                        addressAndCustomer.customer.id, addressAndCustomer),
                Grouped.with(Serdes.Integer(), addressAndCustomerSerde)
            )
            .aggregate( &lt;i class=&quot;conum&quot; data-value=&quot;7&quot;&gt;&lt;/i&gt;&lt;b&gt;(7)&lt;/b&gt;
                CustomerWithAddresses::&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt;,
                (customerId, addressAndCustomer, aggregate) -&amp;gt; aggregate.addAddress(
                        addressAndCustomer),
                (customerId, addressAndCustomer, aggregate) -&amp;gt; aggregate.removeAddress(
                        addressAndCustomer),
                Materialized.with(Serdes.Integer(), customerWithAddressesSerde)
            );

        customersWithAddresses.toStream() &lt;i class=&quot;conum&quot; data-value=&quot;8&quot;&gt;&lt;/i&gt;&lt;b&gt;(8)&lt;/b&gt;
        .to(
                customersWithAddressesTopic,
                Produced.with(Serdes.Integer(), customerWithAddressesSerde)
        );

        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; builder.build();
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;1&quot;&gt;&lt;/i&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;The topic names are injected using the &lt;a href=&quot;https://microprofile.io/project/eclipse/microprofile-config&quot;&gt;MicroProfile Config API&lt;/a&gt;, with the values being provided in the Quarkus &lt;code&gt;application.properties&lt;/code&gt; configuration file (they could be overridden using environment variables for instance)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;2&quot;&gt;&lt;/i&gt;&lt;b&gt;2&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;Create an instance of &lt;code&gt;StreamsBuilder&lt;/code&gt;, which helps us to build our topology&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;3&quot;&gt;&lt;/i&gt;&lt;b&gt;3&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;For serializing and deserializing Java types used in the streaming pipeline into/from JSON, Quarkus provides the &lt;code&gt;class io.quarkus.kafka.client.serialization.JsonbSerde&lt;/code&gt;;
The Serde implementation based is on &lt;a href=&quot;https://github.com/quarkusio/quarkus/blob/master/extensions/kafka-client/runtime/src/main/java/io/quarkus/kafka/client/serialization/JsonbSerde.java&quot;&gt;JSON-B&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;4&quot;&gt;&lt;/i&gt;&lt;b&gt;4&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;The &lt;code&gt;KTable&lt;/code&gt;-&lt;code&gt;KTable&lt;/code&gt; foreign-key join functionality is used to extract the &lt;code&gt;customer#id&lt;/code&gt; and perform the join;
&lt;code&gt;StreamsBuilder#table()&lt;/code&gt; is used to read the two Kafka topics into the KTable &lt;code&gt;addresses&lt;/code&gt; and &lt;code&gt;customers&lt;/code&gt;, respectively&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;5&quot;&gt;&lt;/i&gt;&lt;b&gt;5&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;The message from the &lt;code&gt;addresses&lt;/code&gt; topic is joined with the corresponding &lt;code&gt;customers&lt;/code&gt; topic; the join result contains the data of the customer with one of their addresses&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;6&quot;&gt;&lt;/i&gt;&lt;b&gt;6&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;groupBy()&lt;/code&gt; operation will have the records to be grouped by &lt;code&gt;customer#id&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;7&quot;&gt;&lt;/i&gt;&lt;b&gt;7&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;To produce the nested structure of one customer and all their addresses, the &lt;code&gt;aggregate()&lt;/code&gt; operation is applied to each group of records (customer-address tuples), updating a &lt;code&gt;CustomerWithAddresses&lt;/code&gt; per customer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&quot;conum&quot; data-value=&quot;8&quot;&gt;&lt;/i&gt;&lt;b&gt;8&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;The results of the pipeline are written out to the &lt;code&gt;customersWithAddressesTopic&lt;/code&gt; topic&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;code&gt;CustomerWithAddresses&lt;/code&gt; class keeps track of the aggregated values while the events are processed in the streaming pipeline.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;java&quot;&gt;&lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;CustomerWithAddresses&lt;/span&gt; {

    &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; Customer customer;
    &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;predefined-type&quot;&gt;List&lt;/span&gt;&amp;lt;Address&amp;gt; addresses = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;predefined-type&quot;&gt;ArrayList&lt;/span&gt;&amp;lt;&amp;gt;();

    &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; CustomerWithAddresses addAddress(AddressAndCustomer addressAndCustomer) {

        customer = addressAndCustomer.customer;
        addresses.add(addressAndCustomer.address);

        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;local-variable&quot;&gt;this&lt;/span&gt;;
    }

    &lt;span class=&quot;directive&quot;&gt;public&lt;/span&gt; CustomerWithAddresses removeAddress(AddressAndCustomer addressAndCustomer) {

        &lt;span class=&quot;predefined-type&quot;&gt;Iterator&lt;/span&gt;&amp;lt;Address&amp;gt; it = addresses.iterator();
        &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (it.hasNext()) {
            Address a = it.next();
            &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (a.id == addressAndCustomer.address.id) {
                it.remove();
                &lt;span class=&quot;keyword&quot;&gt;break&lt;/span&gt;;
            }
        }

        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;local-variable&quot;&gt;this&lt;/span&gt;;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Kafka Streams extension is configured via the Quarkus configuration file &lt;code&gt;application.properties&lt;/code&gt;.
Along with the topic names, this file also has the information about the Kafka bootstrap server and several streams options:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;customers.topic=dbserver1.inventory.customers
addresses.topic=dbserver1.inventory.addresses
customers.with.addresses.topic=customers-with-addresses

quarkus.kafka-streams.bootstrap-servers=localhost:9092
quarkus.kafka-streams.application-id=kstreams-fkjoin-aggregator
quarkus.kafka-streams.application-server=${hostname}:8080
quarkus.kafka-streams.topics=${customers.topic},${addresses.topic}

# streams options
kafka-streams.cache.max.bytes.buffering=10240
kafka-streams.commit.interval.ms=1000
kafka-streams.metadata.max.age.ms=500
kafka-streams.auto.offset.reset=earliest
kafka-streams.metrics.recording.level=DEBUG
kafka-streams.consumer.session.timeout.ms=150
kafka-streams.consumer.heartbeat.interval.ms=100&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;building_and_running_the_application&quot;&gt;Building and Running the Application&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can now build the application like so:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;mvn clean package&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To run the application and all related components (Kafka, Kafka Connect with Debezium, a Postgres database), we&amp;#8217;ve created a &lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/master/kstreams-fk-join/docker-compose.yaml&quot;&gt;Docker Compose file&lt;/a&gt;,
which you can find in the &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/kstreams-fk-join&quot;&gt;debezium-examples&lt;/a&gt; repo.
To launch all the containers, also building the aggregator container image, run the the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;export DEBEZIUM_VERSION=1.4

docker-compose up --build&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To register the Debezium Connector with Kafka Connect,
you need to specify the configuration properties like name of the connector, database hostname, user, password, port, name of the database, etc.
Create a file &lt;a href=&quot;https://github.com/debezium/debezium-examples/blob/master/kstreams-fk-join/register-postgres.json&quot;&gt;register-postgres.json&lt;/a&gt; with the following contents:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;connector.class&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;io.debezium.connector.postgresql.PostgresConnector&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;tasks.max&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.hostname&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.port&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;5432&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.user&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.password&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.dbname&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database.server.name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema.include&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;inventory&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;decimal.handling.mode&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;key.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.json.JsonConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;key.converter.schemas.enable&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value.converter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;org.apache.kafka.connect.json.JsonConverter&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;value.converter.schemas.enable&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Configure the Debezium Connector:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;http PUT http://localhost:8083/connectors/inventory-connector/config &amp;lt; register-postgres.json&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now run an instance of the &lt;code&gt;debezium/tooling&lt;/code&gt; container image:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;docker run --tty --rm \
    --network kstreams-fk-join-network \
    debezium/tooling:1.1 \&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This image provides several useful tools such as &lt;a href=&quot;https://github.com/edenhill/kafkacat&quot;&gt;kafkacat&lt;/a&gt;. Within the tooling container, run kafkacat to examine the results of the streaming pipeline:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;kafkacat -b kafka:9092 -C -o beginning -q \
    -t customers-with-addresses | jq .&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You should see records like the following, each containing all the data of one customer and all their addresses:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{
  &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;addresses&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [
    {
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Hamburg&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Canada&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;100001&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;street&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;42 Main Street&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;zipcode&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;90210&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;
    },
    {
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Berlin&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Canada&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customer_id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;100002&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;street&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;11 Post Dr.&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;zipcode&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;90211&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;
    }
  ],
  &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;sally.thomas@acme.com&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Sally&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;last_name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Thomas&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Get a shell for the database, insert, update, or delete some records, and the join will be reprocessed automatically:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;&lt;span class=&quot;error&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;\&lt;/span&gt;
        &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;\&lt;/span&gt;
        &lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;:&lt;span class=&quot;float&quot;&gt;1.1&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;\&lt;/span&gt;
        &lt;span class=&quot;error&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;:&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;:&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;:&lt;span class=&quot;integer&quot;&gt;5432&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;'&lt;/span&gt;

&lt;span class=&quot;error&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;:

&lt;span class=&quot;error&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;'&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;integer&quot;&gt;1001&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;running_natively&quot;&gt;Running Natively&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Kafka Streams applications can easily be scaled out i.e. the load is going to be shared amongst multiple instances of the application,
each processing  a sub-set of the partitions of the input topics.
When the Quarkus application gets compiled into native code via GraalVM, it takes considerably less memory and has a very fast start-up time.
Without any concern about the memory management, you can start multiple instances of a Kafka Streams pipeline in parallel.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you want to run this application in &lt;code&gt;native&lt;/code&gt; mode, set the &lt;code&gt;QUARKUS_MODE&lt;/code&gt; as &lt;code&gt;native&lt;/code&gt; and run the following
(make sure to have the required GraalVM tooling installed):&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;mvn clean package -Pnative&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To learn more about running Kafka Streams applications as a native binary, please refer to the &lt;a href=&quot;https://quarkus.io/guides/kafka-streams#running-natively&quot;&gt;reference guide&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;more_insights_on_the_kafka_streams_extension&quot;&gt;More Insights on the Kafka Streams Extension&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Quarkus extension can also help you address some of the common requirements when building microservices for stream processing.
For running your Kafka Streams application in production, you can for instance easily add health checks and metrics for the data pipeline.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://quarkus.io/guides/microprofile-metrics&quot;&gt;Micrometer Metrics&lt;/a&gt; provides rich metrics about your Quarkus application, i.e. what is happening inside your application by monitoring and what are its performance characteristics.
Quarkus lets you expose these metrics via HTTP using a JSON format or the OpenMetrics format.
From there, they can be scraped by tools such as &lt;a href=&quot;https://prometheus.io/&quot;&gt;Prometheus&lt;/a&gt; and stored for analysis and visualization.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once the application is started, the metrics will be exposed under &lt;code&gt;q/metrics&lt;/code&gt;, returning the data in the OpenMetrics format by default:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;properties&quot;&gt;# HELP kafka_producer_node_request_total The total number of requests sent
# TYPE kafka_producer_node_request_total counter
kafka_producer_node_request_total{client_id=&amp;quot;kstreams-fkjoin-aggregator-b4ac1384-0e0a-4f19-8d52-8cc1ee4c6dfe-StreamThread-1-producer&amp;quot;,kafka_version=&amp;quot;2.5.0&amp;quot;,node_id=&amp;quot;node--1&amp;quot;,status=&amp;quot;up&amp;quot;,} 83.0
# HELP kafka_producer_record_send_rate The average number of records sent per second.
# TYPE kafka_producer_record_send_rate gauge
kafka_producer_record_send_rate{client_id=&amp;quot;kstreams-fkjoin-aggregator-b4ac1384-0e0a-4f19-8d52-8cc1ee4c6dfe-StreamThread-1-producer&amp;quot;,kafka_version=&amp;quot;2.5.0&amp;quot;,status=&amp;quot;up&amp;quot;,} 0.0
# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the (young) heap memory pool after one GC to before the next
# TYPE jvm_gc_memory_allocated_bytes_total counter
jvm_gc_memory_allocated_bytes_total 1.1534336E8
# ...
# HELP http_requests_total
# TYPE http_requests_total counter
http_requests_total{status=&amp;quot;up&amp;quot;,uri=&amp;quot;/api/customers&amp;quot;,} 0.0
# ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you aren’t using Prometheus, you have a few options like Datadog, Stackdriver, and others.
For a detailed guide check the &lt;a href=&quot;https://github.com/quarkiverse/quarkus-micrometer-registry&quot;&gt;Quarkiverse Extensions&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;On the other hand, we have &lt;a href=&quot;https://quarkus.io/guides/microprofile-health&quot;&gt;MicroProfile Health&lt;/a&gt; spec, which provides information about the liveness of the application,
i.e. signalling whether your application is running or not and whether your application is able to process requests.
To monitor the health status of your existing Quarkus application you can add the &lt;code&gt;smallrye-health&lt;/code&gt; extension:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;mvn quarkus:add-extension -Dextensions=&quot;smallrye-health&quot;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Quarkus will expose all health checks via HTTP under &lt;code&gt;q/health&lt;/code&gt;, which in our case shows the status of the pipeline and any missing topics:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;DOWN&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;checks&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [
        {
            &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Kafka Streams topics health check&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
            &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;DOWN&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
            &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {
                &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;missing_topics&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;dbserver1.inventory.customers,dbserver1.inventory.addresses&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;
            }
        }
    ]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Quarkus extension for Kafka Streams comes with everything needed to run stream processing pipelines on the JVM as well as in native mode, along with additional bonuses of performing health checks, metrics, and more.
For instance you could quite easily expose REST APIs for interactive queries using the Quarkus REST support,
potentially retrieving data from other instances of scaled out Kafka Streams app using the &lt;a href=&quot;https://quarkus.io/guides/rest-client&quot;&gt;MicroProfile REST client API&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article we have discussed a stream processing topology of foreign key joins in Kafka Streams, and how to use the Quarkus Kafka Streams extension for running and building your application in JVM mode.
You can find the complete &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/kstreams-fk-join&quot;&gt;source code&lt;/a&gt; of the implementation in the Debezium examples repo.
If you got any questions or feedback, please let us know in the comments below.
We&amp;#8217;re looking forward to your suggestions!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://quarkus.io/guides/kafka-streams&quot;&gt;Building Kafka Streams applications with Quarkus&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://speakerdeck.com/gunnarmorling/change-data-capture-pipelines-with-debezium-and-kafka-streams-jokerconf&quot;&gt;Change Data Capture Pipelines With Debezium and Kafka Streams&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://micrometer.io/docs/concepts&quot;&gt;Micrometer Application Monitor&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Anisha Mohanty</name></author><category term="kafka streams" /><category term="quarkus" /><category term="examples" /><summary type="html">Kafka Streams is a library for developing stream processing applications based on Apache Kafka. Quoting its docs, &quot;a Kafka Streams application processes record streams through a topology in real-time, processing data continuously, concurrently, and in a record-by-record manner&quot;. The Kafka Streams DSL provides a range of stream processing operations such as a map, filter, join, and aggregate. Non-Key Joins in Kafka Streams Debezium’s CDC source connectors make it easy to capture data changes in databases and push them towards sink systems such as Elasticsearch in near real-time. By default, this results in a 1:1 relationship between tables in the source database, the corresponding Kafka topics, and a representation of the data at the sink side, such as a search index in Elasticsearch. In case of 1:n relationships, say between a table of customers and a table of addresses, consumers often are interested in a view of the data that is a single, nested data structure, e.g. a single Elasticsearch document representing a customer and all their addresses. This is where KIP-213 (&quot;Kafka Improvement Proposal&quot;) and its foreign key joining capabilities come in: it was introduced in Apache Kafka 2.4 &quot;to close the gap between the semantics of KTables in streams and tables in relational databases&quot;. Before KIP-213, in order to join messages from two Debezium change event topics, you&amp;#8217;d typically have to manually re-key at least one of the topics, so to make sure the same key is used on both sides of the join. Thanks to KIP-213, this isn&amp;#8217;t needed any longer, as it allows to join two Kafka topics on fields extracted from the Kafka message value, taking care of the required re-keying automatically, in a fully transparent way. Comparing to previous approaches, this drastically reduces the effort for creating aggregated events from Debezium’s CDC events.</summary></entry><entry><title type="html">Debezium 1.5.0.Beta2 Released</title><link href="https://debezium.io/blog/2021/03/15/debezium-1-5-beta2-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Beta2 Released" /><published>2021-03-15T00:00:00+00:00</published><updated>2021-03-15T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/03/15/debezium-1-5-beta2-released</id><content type="html" xml:base="https://debezium.io/blog/2021/03/15/debezium-1-5-beta2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We are very happy to announce the release of Debezium &lt;strong&gt;1.5.0.Beta2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The main features of this release is the new Debezium Signaling Table support,
Vitess SET type support, and
a continued focus to minor improvements, bugfixes, and polish as we sprint to the finish line for the 1.5 release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Beta2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;54 issues&lt;/a&gt; since the Beta1 release,
some of which we&amp;#8217;ll explore more in-depth below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;signaling_table&quot;&gt;Signaling Table&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The signal table feature is a huge milestone for Debezium.
It provides a command pattern based on a source database table to send commands (aka signals) to Debezium so that specific actions may be taken.
The framework is extendable, allowing a connector to implement custom commands beyond the common commands provided by Debezium core.
There are several situations where this might be applicable, including but not limited to,
PostgreSQL primary key column changes,
changes to enum value-sets of a column definition,
and schema changes with the Oracle connector.
This is an incubating feature and therefore behavior is subject to change between releases.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In order to use the signal table feature, the connector option &lt;code&gt;signal.data.collection&lt;/code&gt; must be specified in the connector&amp;#8217;s configuration.
This option specifies the fully qualified name of the table from which signal requests will be sourced.
If this option is not specified or empty, the signal table feature will be disabled.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The signal table itself must be created ahead of time and it must adhere to the following convention:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-all stretch&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Column Name&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Data Type&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;ID&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;STRING&lt;/code&gt;&lt;br&gt;
The unique identifier of the signal such as a UUID.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;TYPE&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;STRING&lt;/code&gt;&lt;br&gt;
The unique command to be performed.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;DATA&lt;/p&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;p class=&quot;tableblock&quot;&gt;&lt;code&gt;STRING&lt;/code&gt;&lt;br&gt;
The payload for the command.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Lastly, the signal table must be explicitly found as part of your connector&amp;#8217;s include/exclude-list specifications.
In other words, if you&amp;#8217;re specifying a list of tables to monitor, this list will need to be adjusted to include the name of the signal table as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This new feature has quite a number of use cases that we intend to explore in future releases.
Lets discuss what signals are currently supported in this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;log_signal&quot;&gt;Log Signal&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The log signal is detected when the &lt;code&gt;TYPE&lt;/code&gt; column in the signal table is &lt;code&gt;log&lt;/code&gt;.
This signal requests that Debezium write the contents of the &lt;code&gt;DATA&lt;/code&gt; column (payload) to the connector logs as-is.
This can be useful for a variety of purposes from debugging to tracking progress of database script operations and much more.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As an example:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; DEBEZIUM_SIGNALS (ID, TYPE, DATA) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;Hello World&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once that insert is committed and written to the database&amp;#8217;s transaction logs,
Debezium will recognize the signal and will then write &lt;code&gt;Hello World&lt;/code&gt; to the connector logs using the &lt;code&gt;INFO&lt;/code&gt; log level.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;schema_changes_signal&quot;&gt;Schema Changes Signal&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The schema changes signal is detected when the &lt;code&gt;TYPE&lt;/code&gt; column in the signal table is &lt;code&gt;schema-changes&lt;/code&gt;.
This signal tells Debezium to emit a &lt;code&gt;SchemaChangeEvent&lt;/code&gt; to the schema changes topic that is based on the changes supplied in the row&amp;#8217;s &lt;code&gt;DATA&lt;/code&gt; column (payload).
The format of the &lt;code&gt;DATA&lt;/code&gt; column must be given in JSON and an example of the format is below.
Additionally, this signal will also have Debezium update it&amp;#8217;s in-memory representation of the table&amp;#8217;s schema structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As an example, we have a PostgreSQL table &lt;code&gt;s1.a&lt;/code&gt; where we want to add a new column &lt;code&gt;aa&lt;/code&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;json&quot;&gt;{
  &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
  &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;changes&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [{
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;ALTER&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;s1.a&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: {
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;defaultCharsetName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;,
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;primaryKeyColumnNames&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [ &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;pk&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt; ],
      &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: [{
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;pk&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;jdbcType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;4&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;nativeType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;23&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;serial&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeExpression&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;serial&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;charsetName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;10&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;1&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;autoIncremented&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;true&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;generated&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;
      }, {
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;aa&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;jdbcType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;4&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;nativeType&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;23&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;int4&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;typeExpression&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;int4&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;charsetName&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;null&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;10&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;integer&quot;&gt;2&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;true&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;autoIncremented&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;,
        &lt;span class=&quot;key&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;generated&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;value&quot;&gt;false&lt;/span&gt;
      }]
    }
  }]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With this JSON payload, the signal would be inserted as:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;class&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;INTO&lt;/span&gt; DEBEZIUM_SIGNALS (ID, TYPE, DATA) &lt;span class=&quot;keyword&quot;&gt;VALUES&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;content&quot;&gt;schema-changes&lt;/span&gt;&lt;span class=&quot;delimiter&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, &amp;lt;json-payload-string&amp;gt;);&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess_set_support&quot;&gt;Vitess SET support&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Vitess team improved the &lt;code&gt;SET&lt;/code&gt; data type support in the VStream API as part of Vitess 9.0.
This improvement has lead to the &lt;code&gt;SET&lt;/code&gt; data type now being supported by the Debezium Vitess connector.
This data type will be emitted as an &lt;code&gt;EnumSet&lt;/code&gt; that will now contain all the permissible values of the column&amp;#8217;s &lt;code&gt;SET&lt;/code&gt; definition.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other_features_and_fixes&quot;&gt;Other Features and Fixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides the Signal Table and Vitess SET support, a few other improvements and fixes found their way into this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Debezium connector for Oracle now uses the LogMiner-based capturing implementation by default.
In order to use the XStream-based implementation, the &lt;code&gt;database.connection.adapter&lt;/code&gt; option must be explicitly set to &lt;code&gt;xstream&lt;/code&gt; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3241&quot;&gt;DBZ-3241&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In an earlier release of Debezium 1.5, the Oracle connector began to emit &lt;code&gt;NUMBER(1)&lt;/code&gt; data types as &lt;code&gt;BOOLEAN&lt;/code&gt;.
Rather than this conversion be implicitly done by the connector, this behavior has been moved to an OOTB converter, &lt;code&gt;NumberOneToBooleanConverter&lt;/code&gt;,
that can be used as needed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3208&quot;&gt;DBZ-3208&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;System generated index-organized tables (tables that begin with &lt;code&gt;SYS_IOT_OVER&lt;/code&gt;) are ignored by the Oracle connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3036&quot;&gt;DBZ-3036&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium Server&amp;#8217;s sink for AWS Kinesis can be configured with an endpoint by specifying &lt;code&gt;debezium.sink.kinesis.endpoint&lt;/code&gt; (&lt;a href=&quot;https://www.redhat.com/browse/DBZ-3246&quot;&gt;DBZ-3246&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, you can find the complete list of all the addressed issues and upgrade procedures in the &lt;a href=&quot;/release/1.5/release-notes/#release-1.5.0-beta2&quot;&gt;release notes&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks to all the community members contributing to this release:
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ddseapy&quot;&gt;David Seapy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/denisprog&quot;&gt;Victar Malinouski&lt;/a&gt;,
&lt;a href=&quot;https://github.com/fuxiao224&quot;&gt;Xiao Fu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vaosinbi&quot;&gt;Vladimir Osin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/martper2&quot;&gt;Martín Pérez&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/mengqiu&quot;&gt;Meng Qiu&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;whats_next&quot;&gt;What&amp;#8217;s Next?&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Slowly wrapping up the work on the Debezium 1.5 release train,
we&amp;#8217;ve also taken the opportunity and integrated the Debezium Oracle into the main &lt;a href=&quot;https://github.com/debezium/debezium&quot;&gt;debezium&lt;/a&gt; source code repository.
With that, all connectors of the former &lt;a href=&quot;https://github.com/debezium/debezium-incubator&quot;&gt;debezium-incubator&lt;/a&gt; respository have either been moved into their own, dedicated repository, or integrated into the main one.
The incubator repository has been set to &quot;Archived&quot; mode, allowing to examine its history if needed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For the remaining time until 1.5 Final, we&amp;#8217;re planning to focus on bug fixes, performance improvements, documentation adjustments and other stabilization efforts;
barring any unforeseen issues, the LogMiner-based capture implementation will be promoted from &lt;em&gt;Incubating&lt;/em&gt; to &lt;em&gt;Stable&lt;/em&gt; state for the Final release, too.
If things go as planned, there&amp;#8217;ll be a CR (candidate release) mid next week, followed by the final release around the end of the month.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">We are very happy to announce the release of Debezium 1.5.0.Beta2! The main features of this release is the new Debezium Signaling Table support, Vitess SET type support, and a continued focus to minor improvements, bugfixes, and polish as we sprint to the finish line for the 1.5 release. Overall, the community fixed 54 issues since the Beta1 release, some of which we&amp;#8217;ll explore more in-depth below.</summary></entry><entry><title type="html">Debezium 1.5.0.Beta1 Released</title><link href="https://debezium.io/blog/2021/02/24/debezium-1-5-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Beta1 Released" /><published>2021-02-24T00:00:00+00:00</published><updated>2021-02-24T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/02/24/debezium-1-5-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/02/24/debezium-1-5-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m very happy to announce the release of Debezium &lt;strong&gt;1.5.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release adds a brand-new component&amp;#8201;&amp;#8212;&amp;#8201;the web-based Debezium UI --, transaction metadata support for the MySQL connector,
a large number of improvements to the LogMiner-based capture implementation for the Debezium Oracle connector,
support for Vitess 9.0, and much more.
Let&amp;#8217;s explore some of the new features in the following.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;debezium_ui&quot;&gt;Debezium UI&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The different Debezium connectors provide great power and flexibility for setting up and running change data capture sources for a range of databases.
But this flexibility also comes at a cost: getting started with the connectors can take some time for understanding all the different options and their semantics.
Another critical aspect is operating the connectors, i.e. gaining insight into their current status and metrics,
being able to react to connector failures, and more etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Based on this feedback from the community, we &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;have explored&lt;/a&gt; over the last few months how a graphical user interface could help with these matters.
The initial proof-of-concept looked very promising, so we decided to move forward and make the &lt;a href=&quot;https://github.com/debezium/debezium-ui/&quot;&gt;UI&lt;/a&gt; an official component of the Debezium project.
Still under active development, you already can try out the UI today
(available as a &lt;a href=&quot;https://hub.docker.com/r/debezium/debezium-ui&quot;&gt;container image on Docker Hub&lt;/a&gt;) and use it to set up Debezium connectors in your Kafka Connect clusters.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ll follow up with more details on the Debezium UI in a separate blog post within the next few days,
discussing its current status, the roadmap for this component, and more.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;improved_logminer_based_cdc_implementation&quot;&gt;Improved LogMiner-based CDC Implementation&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Continuing our current focus on the LogMiner-based CDC implementation for Oracle,
we&amp;#8217;ve fixed a substantial number of issues for this connector.
Amongst them are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Drastically improved DML parsing performance (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3078&quot;&gt;DBZ-3078&lt;/a&gt;); a new hand-written parser for the LogMiner DML statements allows for better throughput of this connector, the existing external parser implementation will be removed very soon&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for capturing changes from multiple schemas (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3009&quot;&gt;DBZ-3009&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for column filtering (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3167&quot;&gt;DBZ-3167&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Correct transaction metadata (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3090&quot;&gt;DBZ-3090&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Several bug fixes related to log file switching and similar (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2754&quot;&gt;DBZ-2754&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3001&quot;&gt;DBZ-3001&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3153&quot;&gt;DBZ-3153&lt;/a&gt;, etc.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess_connector&quot;&gt;Vitess Connector&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Led by community member Kewei Shang, the Debezium connector for Vitess now supports Vitess 9.0
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3100&quot;&gt;DBZ-3100&lt;/a&gt;).
The connector also can capture changes from JSON and ENUM columns
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3115&quot;&gt;DBZ-3115&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3124&quot;&gt;DBZ-3124&lt;/a&gt;),
and it implements the configuration validation API of Kafka Connect
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3117&quot;&gt;DBZ-3117&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Further fixes and improvements in this release including the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Debezium MySQL connector can expose metadata about transaction boundaries (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3114&quot;&gt;DBZ-3114&lt;/a&gt;);
this is one of the first benefits we obtain by rebasing this connector onto the common Debezium connector framework,
as discussed in the &lt;a href=&quot;/blog/2021/02/08/debezium-1-5-alpha1-released/&quot;&gt;1.5.0.Alpha1&lt;/a&gt; release announcement&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Debezium connector for Postgres is tested and validated against PG 13 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3022&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DBZ-3022&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ability to customize offsets when using the Debezium embedded API (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2897&quot;&gt;DBZ-2897&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Support for &lt;code&gt;CREATE OR REPLACE INDEX&lt;/code&gt; DDL when using the MySQL connector with MariaDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3067&quot;&gt;DBZ-3067&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Infinite timestamp values supported with Postgres (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2614&quot;&gt;DBZ-2614&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, a grand total of &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Beta1%20ORDER%20BY%20component%20ASC&quot;&gt;78 issues&lt;/a&gt; have been addressed for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As always, a big thanks you to all the community members who contributed:
&lt;a href=&quot;https://github.com/adhaamehab&quot;&gt;Adhaam Ehab&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/fahimfarookme&quot;&gt;Fahim Farook&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/harveyyue&quot;&gt;Harvey Yue&lt;/a&gt;,
&lt;a href=&quot;https://github.com/kppullin&quot;&gt;Kevin Pullin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelcizmar&quot;&gt;Michael Cizmar&lt;/a&gt;,
&lt;a href=&quot;https://github.com/nitin456&quot;&gt;Nitin Agarwal&lt;/a&gt;,
&lt;a href=&quot;https://github.com/r-ballard&quot;&gt;Russell Ballard&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mrshanepaul&quot;&gt;Shane Paul&lt;/a&gt;,
&lt;a href=&quot;https://github.com/tprelle&quot;&gt;Thomas Prelle&lt;/a&gt;,
&lt;a href=&quot;https://github.com/twthorn&quot;&gt;Thomas Thornton&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/Cyril-Engels&quot;&gt;Yilong Chang&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I&amp;#8217;m very happy to announce the release of Debezium 1.5.0.Beta1! This release adds a brand-new component&amp;#8201;&amp;#8212;&amp;#8201;the web-based Debezium UI --, transaction metadata support for the MySQL connector, a large number of improvements to the LogMiner-based capture implementation for the Debezium Oracle connector, support for Vitess 9.0, and much more. Let&amp;#8217;s explore some of the new features in the following.</summary></entry><entry><title type="html">Debezium 1.5.0.Alpha1 Released</title><link href="https://debezium.io/blog/2021/02/08/debezium-1-5-alpha1-released/" rel="alternate" type="text/html" title="Debezium 1.5.0.Alpha1 Released" /><published>2021-02-08T00:00:00+00:00</published><updated>2021-02-08T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/02/08/debezium-1-5-alpha1-released</id><content type="html" xml:base="https://debezium.io/blog/2021/02/08/debezium-1-5-alpha1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.5 series, &lt;strong&gt;1.5.0.Alpha1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release brings many improvements to the LogMiner-based capture implementation for the Debezium Oracle connector,
a large overhaul of the MySQL connector,
as well as a wide range of bug fixes and other small feature additions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;improved_logminer_based_capture_implementation&quot;&gt;Improved LogMiner-based Capture Implementation&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Since we&amp;#8217;ve announced the LogMiner-based implementation for the Debezium Oracle connector in &lt;a href=&quot;/blog/2020/10/01/debezium-1-3-final-released/&quot;&gt;Debezium 1.3&lt;/a&gt;,
we&amp;#8217;ve seen a constantly growing interest in this connector by folks from our lively community,
who tested it out, provided feedback, logged bug reports and feature requests, submitted pull requests with fixes, and more.
Based on all this input, the connector is rapidly maturing, and we aim to move the LogMiner-based implementation from &quot;Incubating&quot; to &quot;Stable&quot; state in Debezium 1.5, or 1.6 the latest.
This first Alpha release of Debezium 1.5 contains a number of related improvements:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;java.sql.SQLException: ORA-01333: failed to establish Logminer Dictionary (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2939&quot;&gt;DBZ-2939&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Capture and report LogMiner state when mining session fails to start (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3055&quot;&gt;DBZ-3055&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium Oracle Connector will appear stuck on large SCN jumps (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2982&quot;&gt;DBZ-2982&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improve logging for Logminer adapter (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2999&quot;&gt;DBZ-2999&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Many thanks Martín Pérez, Milo van der Zee, Anton Kondratev, and all the others for their intensive testing, feedback, and contributions while working on this!
One of the next steps in this area will be several performance-related improvements; stay tuned for the details.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;reworked_mysql_connector&quot;&gt;Reworked MySQL Connector&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In order to reduce the maintenance effort for all the different Debezium connectors,
we&amp;#8217;ve started work towards a common connector framework long time ago.
This framework allows us to implement many features (and bug fixes) just once,
and all the connectors based on this framework will be able to benefit from it.
By now, almost all of the Debezium connectors have been ported to this framework,
with the exception of the Cassandra and MySQL connectors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As of this release, also the MySQL connector provides an implementation based on this framework.
Since the MySQL connector has been the first one amongst the Debezium connectors, and it has quite a few specific characteristics and features,
we have decided to not simply replace the existing implementation with a new one,
but rather keep both, existing and new, side by side for some time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This allows the new implementation to mature, also giving users the choice of which implementation to use.
While the new connector implementation is the default one as of this release,
you can go back to the earlier one by setting the &lt;code&gt;internal.implementation&lt;/code&gt; option to &lt;code&gt;legacy&lt;/code&gt;.
We don&amp;#8217;t have any immediate plans for removing the existing implementation,
but focus for feature work and bug fixes will shift to the new implementation going forward.
Please give the new connector implementation a try and let us know if you encounter any issues with it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While the new implementation is largely on par feature-wise with with the earlier one,
there&amp;#8217;s one exception: the previous, experimental support for changing the filter configuration of a connector instance isn&amp;#8217;t part of the new implementation.
We&amp;#8217;re planning to roll out a comparable feature for all the framework-based connectors in the near future.
Now that there also is a framework-based implementation for the MySQL connector,
we&amp;#8217;re planning to provide a range of improvements to snapshotting for all the (relational) connectors:
for instance the aforementioned capability to change filter configurations,
means of parallelizing snapshot operations, and more.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;other_features&quot;&gt;Other Features&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Besides these key features, there&amp;#8217;s a range of other improvements, smaller new features, and bug fixes coming with this release, including the following:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Correct handling of lists of user types in the Cassandra connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2974&quot;&gt;DBZ-2974&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple DDL parser fixes for MySQL and MariaDB (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3018&quot;&gt;DBZ-3018&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3020&quot;&gt;DBZ-3020&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3023&quot;&gt;DBZ-3023&lt;/a&gt;, &lt;a href=&quot;https://issues.redhat.com/browse/DBZ-3039&quot;&gt;DBZ-3039&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Better snapshotting performance for large Postgres schemas with many tables (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2575&quot;&gt;DBZ-2575&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ability to emit &lt;code&gt;TRUNCATE&lt;/code&gt; events via the Postgres connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2382&quot;&gt;DBZ-2382&lt;/a&gt;); note that, when enabled, this adds a new &lt;code&gt;op&lt;/code&gt; type &lt;code&gt;t&lt;/code&gt; for this connector&amp;#8217;s change events, so please ensure your consumers can handle such events gracefully&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Thanks to the work of &lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;, there is now instructions for following the Debezium tutorial example &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/tutorial#using-vitess&quot;&gt;using the incubating connector for Vitess&lt;/a&gt;
(&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2678&quot;&gt;DBZ-2678&lt;/a&gt;),
which was added in Debezium 1.4:&lt;/p&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/vitess-sharding-setup.png&quot; class=&quot;responsive-image&quot; alt=&quot;Vitess Tutorial Example Overview&quot; style=&quot;max-width:90%;&quot;&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.5.0.Alpha1%20ORDER%20BY%20component%20ASC&quot;&gt;32 issues&lt;/a&gt; were fixed for this release.
A big thank you goes out to all the community members who contributed:
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/davecramer&quot;&gt;Dave Cramer&lt;/a&gt;
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martín Pérez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/msillence&quot;&gt;Martin Sillence&lt;/a&gt;,
&lt;a href=&quot;https://github.com/pkpfr&quot;&gt;Nick Murray&lt;/a&gt;,
and &lt;a href=&quot;https://github.com/krnaveen14&quot;&gt;Naveen Kumar&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For the upcoming 1.5 preview releases, we&amp;#8217;re planning to focus on further improving and stabilizing the LogMiner-based connector implementation for Oracle,
wrap up some loose ends around the MySQL connector migration, and begin to explore the aforementioned snapshotting improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ve also made the decision to continue our efforts for creating a &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;graphical Debezium user interface&lt;/a&gt;;
this component is currently under active development, with support for more connectors, functionality for (re-)starting and stopping connectors, examining logs, and much more in the workings.
If things go as planned, the UI will officially be part of the next Debezium 1.5 preview release!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">It&amp;#8217;s my pleasure to announce the first release of the Debezium 1.5 series, 1.5.0.Alpha1! This release brings many improvements to the LogMiner-based capture implementation for the Debezium Oracle connector, a large overhaul of the MySQL connector, as well as a wide range of bug fixes and other small feature additions.</summary></entry><entry><title type="html">Debezium 1.4.1.Final Released</title><link href="https://debezium.io/blog/2021/01/28/debezium-1-4-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.4.1.Final Released" /><published>2021-01-28T00:00:00+00:00</published><updated>2021-01-28T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/28/debezium-1-4-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/01/28/debezium-1-4-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We highly recommend upgrading from 1.4.0.Final and earlier versions as this release includes bug fixes and enhancements to several Debezium connectors which includes some of the following:
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] - Use collation to get charset when charset is not set (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2922&quot;&gt;DBZ-2922&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] - Debezium Connectors are failing while reading binlog: Unknown event type 100 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2499&quot;&gt;DBZ-2499&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] - Some column default values are not extracted correctly while reading table structure (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2698&quot;&gt;DBZ-2698&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] - Default database charset is not recorded (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2921&quot;&gt;DBZ-2921&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] - Labeled create procedure&amp;#8217;s body is not parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2972&quot;&gt;DBZ-2972&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - Supplemental logging is required for entire database rather than per monitored table (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2711&quot;&gt;DBZ-2711&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - Missing log file error when current SCN differs from snapshotted in Oracle connector and Logminer (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2855&quot;&gt;DBZ-2855&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - DML statements longer than 4000 characters are incorrectly combined from V$LOGMNR_CONTENTS (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2920&quot;&gt;DBZ-2920&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - Snapshot causes ORA-08181 exception (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2949&quot;&gt;DBZ-2949&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - Deadlock in the XStream handler and offset commiter call concurrently (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2891&quot;&gt;DBZ-2891&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - Debezium swallows DML exception in certain cases (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2981&quot;&gt;DBZ-2981&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] - Implement Scn as a domain type (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2518&quot;&gt;DBZ-2518&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[PostgreSQL] - Instable test: PostgresConnectorIT#testCustomSnapshotterSnapshotCompleteLifecycleHook() (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2938&quot;&gt;DBZ-2938&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[PostgreSQL] - Postgres connector config validation fails because current connector is occupying replication slot (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2952&quot;&gt;DBZ-2952&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[SQL Server] - Add support for binary.handling.mode to the SQL Server connector (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2912&quot;&gt;DBZ-2912&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[SQL Server] - Retry on &quot;The server failed to resume the transaction&quot; (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2959&quot;&gt;DBZ-2959&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Vitess] - Sanitise DECIMAL string from VStream (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2906&quot;&gt;DBZ-2906&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Vitess] - Vitess Connector download link missing on website (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2907&quot;&gt;DBZ-2907&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Dependencies] - Upgrade to Apache Kafka Connect 2.6.1 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2630&quot;&gt;DBZ-2630&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.1.Final&quot;&gt;35 issues&lt;/a&gt; were resolved in this release.
Please refer to the &lt;a href=&quot;/releases/1.4/release-notes/#release-1.4.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to everyone who helped test and identify these bugs and contributed to this release:
&lt;a href=&quot;https://github.com/ahmedjami&quot;&gt;Ahmed Eljami&lt;/a&gt;,
&lt;a href=&quot;https://github.com/isopropylcyanide&quot;&gt;Aman Garg&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ant0nk&quot;&gt;Anton Kondratev&lt;/a&gt;,
&lt;a href=&quot;https://github.com/zxxz&quot;&gt;Giovanni De Stefano&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ismailsimsek&quot;&gt;Ismail Simsek&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mpermar&quot;&gt;Martin Perez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/NishantSinghChandel&quot;&gt;Nishant Singh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/victorxiang30&quot;&gt;Shuguang Xiang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/siufay325&quot;&gt;siufay325&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/tjg184&quot;&gt;Troy Gaines&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="debezium-server" /><category term="outbox" /><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.1.Final! We highly recommend upgrading from 1.4.0.Final and earlier versions as this release includes bug fixes and enhancements to several Debezium connectors which includes some of the following:</summary></entry><entry><title type="html">Debezium 1.4.0.Final Released</title><link href="https://debezium.io/blog/2021/01/07/debezium-1-4-final-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Final Released" /><published>2021-01-07T00:00:00+00:00</published><updated>2021-01-07T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/07/debezium-1-4-final-released</id><content type="html" xml:base="https://debezium.io/blog/2021/01/07/debezium-1-4-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I am pleased to announce the release of Debezium &lt;strong&gt;1.4.0.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release concludes the major work put into Debezium over the last three months.
Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20in%20(1.4.0.Final%2C%201.4.0.Alpha1%2C%201.4.0.Beta1%2C%201.4.0.CR1)%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;117 issues&lt;/a&gt; during that time, including the following key features and changes:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New &lt;a href=&quot;/documentation/reference/connectors/vitess.html&quot;&gt;Vitess&lt;/a&gt; connector, featured in an in-depth &lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;blog post&lt;/a&gt; by Kewei Shang&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fine-grained selection of snapshotted tables&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; completion hook&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Distributed &lt;a href=&quot;/blog/2020/12/16/distributed-tracing-with-debezium/&quot;&gt;Tracing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL support for &lt;em&gt;create&lt;/em&gt; or &lt;em&gt;read&lt;/em&gt; records emitted during snapshot&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Many Oracle &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;Logminer adapter&lt;/a&gt; improvements&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Full support for Oracle JDBC connection strings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Improved reporting of DDL errors&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Please refer to previous release announcements (&lt;a href=&quot;/blog/2020/10/23/debezium-1-4-alpha1-released/&quot;&gt;Alpha1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/11/17/debezium-1-4-alpha2-released/&quot;&gt;Alpha2&lt;/a&gt;, &lt;a href=&quot;/blog/2020/12/09/debezium-1-4-beta1-released/&quot;&gt;Beta1&lt;/a&gt;, &lt;a href=&quot;/blog/2020/12/17/debezium-1-4-cr1-released/&quot;&gt;CR1&lt;/a&gt;) for more details.
Since the CR1 release just before the holidays, we&amp;#8217;ve &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Final%20ORDER%20BY%20issuetype%20DESC%2C%20updated%20DESC%2C%20priority%20DESC&quot;&gt;focused&lt;/a&gt; on addressing some remaining bugs and improvements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Thank you to everyone involved in testing the previous releases, this is invaluable by spotting and addressing any problems with new features as well as regressions.
And of course we&amp;#8217;d like to thank all the community members contributing to this release:
&lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bingqinzhou&quot;&gt;Bingqin Zhou&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Faizan&quot;&gt;Faizan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/martper2&quot;&gt;Martin Perez&lt;/a&gt;,
&lt;a href=&quot;https://github.com/michaelwang&quot;&gt;Michael Wang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;
&lt;a href=&quot;https://github.com/jgormley6&quot;&gt;James Gormley&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jinguangyang&quot;&gt;jinguangyang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/KaushikIyer16&quot;&gt;Kaushik Iyer&lt;/a&gt;,
&lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/seeekr&quot;&gt;Denis Andrejew&lt;/a&gt;,
&lt;a href=&quot;https://github.com/telnicky&quot;&gt;Travis Elnicky&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/yimingl17&quot;&gt;Yiming Liu&lt;/a&gt;,
&lt;a href=&quot;https://github.com/yrodiere&quot;&gt;Yoann Rodière&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, more than 245 individuals have contributed to the Debezium project and the number of Debezium &lt;a href=&quot;/community/users/&quot;&gt;users&lt;/a&gt; continues to grow.
As we usher in 2021, check out our &lt;a href=&quot;/blog/2021/01/06/debezium-2020-recap/&quot;&gt;recap of Debezium in 2020&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;With 1.4 Final released, planning for the 1.5 version (due by the end of March) is currently underway.
The &lt;a href=&quot;/roadmap/&quot;&gt;roadmap&lt;/a&gt; is still being discussed, so be sure to let us know about your requirements and feature requests.
Some of the things we&amp;#8217;re considering for this next release are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Moving the MySQL connector to the CDC connector framework shared by most other Debezium connectors; this will drastically reduce maintenance burden of this connector in the future&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exploring more powerful snapshotting options (e.g. for parallelization and re-doing snapshots of selected tables)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Continued stability and improvements to the new LogMiner-based implementation for Oracle&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Until then remain safe, it&amp;#8217;s onwards and upwards from here!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I am pleased to announce the release of Debezium 1.4.0.Final! This release concludes the major work put into Debezium over the last three months. Overall, the community fixed 117 issues during that time, including the following key features and changes: New Vitess connector, featured in an in-depth blog post by Kewei Shang Fine-grained selection of snapshotted tables PostgreSQL Snapshotter completion hook Distributed Tracing MySQL support for create or read records emitted during snapshot Many Oracle Logminer adapter improvements Full support for Oracle JDBC connection strings Improved reporting of DDL errors</summary></entry><entry><title type="html">Debezium in 2020 – The Recap!</title><link href="https://debezium.io/blog/2021/01/06/debezium-2020-recap/" rel="alternate" type="text/html" title="Debezium in 2020 – The Recap!" /><published>2021-01-06T00:00:00+00:00</published><updated>2021-01-06T00:00:00+00:00</updated><id>https://debezium.io/blog/2021/01/06/debezium-2020-recap</id><content type="html" xml:base="https://debezium.io/blog/2021/01/06/debezium-2020-recap/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A Happy New Year to the Debezium Community!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;May all your endavours be successful, your data be consistent, and most importantly, everyone stay safe and healthy.
With 2020 in the books, I thought it&amp;#8217;d be nice to take a look back and do a quick recap of what has happened around Debezium over the last year.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;First, some facts and numbers for you stats lovers out there:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;After the release of &lt;a href=&quot;/blog/2019/12/18/debezium-1-0-0-final-released/&quot;&gt;Debezium 1.0&lt;/a&gt; in December 2019, we successfully released a stable Debezium version at the end of each quarter, with preview releases roughly every three weeks&lt;sup class=&quot;footnote&quot;&gt;[&lt;a id=&quot;_footnoteref_1&quot; class=&quot;footnote&quot; href=&quot;#_footnotedef_1&quot; title=&quot;View footnote.&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;About 1,400 commits in the core repo (plus many more in the other ones), 36 blog posts and release announcements, 166 threads on the &lt;a href=&quot;https://groups.google.com/g/debezium/&quot;&gt;mailing list&lt;/a&gt; (if the query in my Google inbox is to be trusted)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;About 100 new contributors, bringing the &lt;a href=&quot;https://github.com/debezium/debezium/blob/master/COPYRIGHT.txt&quot;&gt;overall number&lt;/a&gt; of people contributing to the Debezium core repo to 245, plus additional people contributing to the other repositories of the Debezium GitHub organization&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The first &lt;a href=&quot;https://developers.redhat.com/blog/2020/04/14/capture-database-changes-with-debezium-apache-kafka-connectors/&quot;&gt;GA release&lt;/a&gt; of the commercially supported Debezium offering by Red Hat, as part of &lt;a href=&quot;https://www.redhat.com/en/products/integration&quot;&gt;Red Hat Integration&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;/blog/2020/07/28/hello-debezium/&quot;&gt;Two&lt;/a&gt; &lt;a href=&quot;/blog/2020/10/27/hello-debezium/&quot;&gt;new&lt;/a&gt; members on the core engineering team&amp;#8201;&amp;#8212;&amp;#8201;the more, the merrier!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;About 1,600 additional GitHub ⭐s for the Debezium core repo, bringing the total number of star gazers to more than 4,100&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/github_stars_2020.png&quot; style=&quot;max-width:75%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While those figures give a nice impression of the overall activity of Debezium, they don&amp;#8217;t really tell &lt;em&gt;what&lt;/em&gt; has been happening exactly.
What&amp;#8217;s behind the numbers?
Here are some of my personal Debezium highlights from the last year:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two new, community-led Debezium connectors for &lt;a href=&quot;https://github.com/debezium/debezium-connector-db2/&quot;&gt;Db2&lt;/a&gt; and &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess&lt;/a&gt;;
a big shout-out to the engineers of &lt;a href=&quot;/blog/2020/03/05/db2-cdc-approaches/&quot;&gt;IBM&lt;/a&gt; and &lt;a href=&quot;/blog/2020/11/04/streaming-vitess-at-bolt/&quot;&gt;Bolt&lt;/a&gt;, respectively, for stepping up and taking the lead of these connectors!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Besides these new connectors, each of the releases brought a wide range of new features; some of the things I&amp;#8217;m most excited about are &lt;a href=&quot;/documentation/reference/1.2/operations/debezium-server.html&quot;&gt;Debezium Server&lt;/a&gt; for integrating Debezium with message infrastructure like Apache Pulsar, AWS Kinesis, Google Cloud Pub/Sub, and Azure Event Hubs, the &lt;a href=&quot;/documentation/reference/1.1/integrations/outbox.html&quot;&gt;Quarkus extension&lt;/a&gt; for implementing the outbox pattern,
the new &lt;a href=&quot;/documentation/reference/connectors/oracle.html#_logminer&quot;&gt;LogMiner-based connector implementation&lt;/a&gt; for ingesting change events from Oracle,
transaction markers, support for CloudEvents, and so much more!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Integration of Debezium by multiple open-source projects,
e.g. &lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/formats/debezium.html&quot;&gt;Apache Flink&lt;/a&gt;,
&lt;a href=&quot;https://spring.io/blog/2020/12/14/case-study-change-data-capture-cdc-analysis-with-cdc-debezium-source-and-analytics-sink-in-real-time&quot;&gt;Spring Cloud Stream&lt;/a&gt;,
&lt;a href=&quot;https://jet-start.sh/docs/tutorials/cdc&quot;&gt;Hazecast Jet&lt;/a&gt;, and
&lt;a href=&quot;https://camel.apache.org/blog/2020/05/CdcWithCamelAndDebezium/&quot;&gt;Apache Camel&lt;/a&gt;.
Further integrators of Debezium include &lt;a href=&quot;https://materialize.io/docs/third-party/debezium/&quot;&gt;Materialize&lt;/a&gt;, &lt;a href=&quot;https://cloud.google.com/blog/products/data-analytics/how-to-move-data-from-mysql-to-bigquery&quot;&gt;Google Cloud DataFlow&lt;/a&gt; and &lt;a href=&quot;https://devcenter.heroku.com/articles/heroku-data-connectors&quot;&gt;Heroku’s streaming data connectors&lt;/a&gt;.
Here on this blog, we also discussed how to integrate and use Debezium with technologies such as &lt;a href=&quot;/blog/2020/03/19/integration-testing-for-change-data-capture-with-testcontainers/&quot;&gt;Testcontainers&lt;/a&gt;,
the &lt;a href=&quot;/blog/2020/04/09/using-debezium-with-apicurio-api-schema-registry/&quot;&gt;Apicurio API and schema registry&lt;/a&gt;,
and &lt;a href=&quot;/blog/2020/12/16/distributed-tracing-with-debezium/&quot;&gt;OpenTracing&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debezium being &lt;a href=&quot;https://www.thoughtworks.com/radar/platforms/debezium&quot;&gt;listed at &quot;Trial&quot; level&lt;/a&gt; on the ThoughtWorks Tech Radar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A proof-of-concept for a &lt;a href=&quot;/blog/2020/10/22/towards-debezium-ui/&quot;&gt;graphical user interface for configuring and operating Debezium&lt;/a&gt;;
stay tuned for more details here, as this is currently in the process of being built out for other connectors&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The year also brought a large number of blog posts and presentations from the community about their experiences with Debezium.
You can find our full list of Debezium-related resources &lt;a href=&quot;debezium.io/documentation/online-resources/&quot;&gt;here&lt;/a&gt;
(please send a PR for adding anything you think should be listed there).
Some contents I particularly enjoyed include:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://static.sched.com/hosted_files/ossna2020/c6/Managing Data Consistency with Debezium.pdf&quot;&gt;&quot;Managing Data Consistency Among Microservices with Debezium&quot;&lt;/a&gt; by Justin Chao&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://noti.st/morsapaes/liQzgs/change-data-capture-with-flink-sql-and-debezium&quot;&gt;&quot;Change Data Capture with Flink SQL and Debezium&quot;&lt;/a&gt; by Marta Paes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=6nU9i022yeY&quot;&gt;&quot;Microservices &amp;amp; Data: Implementing the Outbox Pattern with Debezium&quot;&lt;/a&gt; by Thorben Janssen&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.systemcraftsman.com/2020/11/30/asap-the-storified-demo-of-introduction-to-debezium-and-kafka-on-kubernetes/&quot;&gt;&quot;ASAP! – The Storified Demo of Introduction to Debezium and Kafka on Kubernetes&quot;&lt;/a&gt; by Aykut Bulgu&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://elephanttamer.net/?p=50&quot;&gt;&quot;Setting up PostgreSQL for Debezium&quot;&lt;/a&gt; by Michał Mackiewicz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@midhunsukumaran.mec/a-year-and-a-half-with-debezium-f4f323b4909d&quot;&gt;&quot;A year and a half with Debezium: CDC With MySQL&quot;&lt;/a&gt; by Midhun Sukumaran&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://developers.redhat.com/cheat-sheets/debezium-openshift-cheat-sheet&quot;&gt;&quot;Debezium on OpenShift Cheat Sheet&quot;&lt;/a&gt; by Abdellatif Bouchama&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@changeant/implementing-the-transactional-outbox-pattern-with-debezium-in-quarkus-f2680306951&quot;&gt;&quot;Implementing the Transactional Outbox pattern with Debezium in Quarkus&quot;&lt;/a&gt; by Iain Porter&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.confluent.io/blog/cdc-and-streaming-analytics-using-debezium-kafka/&quot;&gt;&quot;Analysing Changes with Debezium and Kafka Streams&quot;&lt;/a&gt; by Mike Fowler&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@bogdan.dina03/de-coupling-yourself-507a15fa100d&quot;&gt;&quot;(De)coupling yourself&quot;&lt;/a&gt; by Dina Bogdan&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@limadelrey/kafka-connect-how-to-create-a-real-time-data-pipeline-using-change-data-capture-cdc-c60e06e5306a&quot;&gt;&quot;Kafka Connect: How to create a real time data pipeline using Change Data Capture (CDC)&quot;&lt;/a&gt; by Francisco Lima&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://dev.to/abhirockzz/tutorial-set-up-a-change-data-capture-architecture-on-azure-using-debezium-postgres-and-kafka-49h6&quot;&gt;&quot;Tutorial: Set up a Change Data Capture architecture on Azure using Debezium, Postgres and Kafka &quot;&lt;/a&gt; by Abhishek Gupta&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is just so amazing to see how engaged and helpful this community is; A big thank you to everyone for writing and talking about your experiences with Debezium and change data capture!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I think 2020 has been a great year for the Debezium community,
and I couldn&amp;#8217;t be happier about all the things we&amp;#8217;ve achieved together.
Again, a huge thank you to each and everyone in the community contributing to the project,
be it via by implementing features and bug fixes, reporting issues, engaging in discussions, answering questions on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/debezium&quot;&gt;Stack Overflow&lt;/a&gt;, helping to spread the word in blog posts and conference talks, or otherwise!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What&amp;#8217;s on the roadmap for this year?
It&amp;#8217;s fair to say: &quot;A lot&quot; :) E.g. we&amp;#8217;d like to rework the way snapshots are done: they should be parallelizeable, updates to the include/exclude filters should be possible, and more.
The Debezium UI will see substantial expansion and improvements. We&amp;#8217;re planning to conduct a systematic performance profiling and improvements of identified bottlenecks. There may be official support for MariaDB, as well as an operator for running Debezium Server on Kubernetes.
Plus some super-cool things I cannot talk about at this point yet :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Onwards and Upwards!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;footnotes&quot;&gt;
&lt;hr&gt;
&lt;div class=&quot;footnote&quot; id=&quot;_footnotedef_1&quot;&gt;
&lt;a href=&quot;#_footnoteref_1&quot;&gt;1&lt;/a&gt;. Where is Debezium 1.4, you ask? The agile bunch we are, we adhered to the &quot;Individuals over processes&quot; principle and decided to move this release to later this week, due to the holiday break :)
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Gunnar Morling</name></author><category term="discussion" /><summary type="html">A Happy New Year to the Debezium Community! May all your endavours be successful, your data be consistent, and most importantly, everyone stay safe and healthy. With 2020 in the books, I thought it&amp;#8217;d be nice to take a look back and do a quick recap of what has happened around Debezium over the last year. First, some facts and numbers for you stats lovers out there:</summary></entry><entry><title type="html">Debezium 1.4.0.CR1 Released</title><link href="https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.CR1 Released" /><published>2020-12-17T00:00:00+00:00</published><updated>2020-12-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/12/17/debezium-1-4-cr1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.0.CR1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release focuses primarily on polishing the 1.4 release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.CR1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;15 issues&lt;/a&gt; for this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Document &quot;database.oracle.version&quot; option &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2603&quot;&gt;DBZ-2603&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move Cassandra connector to separate repository &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2636&quot;&gt;DBZ-2636&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove link in MySQL docs section that points to the same section &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2710&quot;&gt;DBZ-2710&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Invalid column name should fail connector with meaningful message &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2836&quot;&gt;DBZ-2836&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix typos in downstream ModuleID declarations in monitoring.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2838&quot;&gt;DBZ-2838&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Duplicate anchor ID in partials/ref-connector-monitoring-snapshot-metrics.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2839&quot;&gt;DBZ-2839&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oracle schema history events fail on partitioned table &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2841&quot;&gt;DBZ-2841&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fix additional typo in ModuleID declaration in monitoring.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2843&quot;&gt;DBZ-2843&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit modularization annotations in logging.adoc &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2846&quot;&gt;DBZ-2846&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;outbox extension emits UPDATE events when delete is disabled &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2847&quot;&gt;DBZ-2847&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update Groovy version to 3.0.7 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2850&quot;&gt;DBZ-2850&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;outlook&quot;&gt;Outlook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Barring any unforeseen regressions and bug reports, Debezium 1.4 Final should be out the first week of January.
Until then, we wish everyone a safe and happy holiday season!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.0.CR1! This release focuses primarily on polishing the 1.4 release.</summary></entry><entry><title type="html">Distributed Tracing with Debezium</title><link href="https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium/" rel="alternate" type="text/html" title="Distributed Tracing with Debezium" /><published>2020-12-16T11:00:00+00:00</published><updated>2020-12-16T11:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium</id><content type="html" xml:base="https://debezium.io/blog/2020/12/16/distributed-tracing-with-debezium/">&lt;div id=&quot;preamble&quot;&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The current pattern in application development gravitates toward microservices and microservices architecture.
While this approach gives the developer teams great flexibility in terms of independent deployments and development velocity, the drawback is at hand when you try to track a bug in production.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Monolithic applications sit nicely at a single place so you can introspect the code flows and the application&amp;#8217;s runtime state.
This is more challenging with microservice architectures, as a single business transaction can span across tens of services deployed in separate processes and compute nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You can rely on traditional methods like logging where you need to collect and correlate logs at a single place, so you can try to reconstruct the business transaction path.
This is one of the tools in the box we can use, but it still can be crude and it will not provide all the necessary context.
&lt;a href=&quot;https://microservices.io/patterns/observability/distributed-tracing.html&quot;&gt;Distributed Tracing&lt;/a&gt; comes here to the rescue.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;distributed_tracing&quot;&gt;Distributed Tracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Distributed tracing allows services to leave breadcrumbs during the execution with enough information to create an execution path of the business transaction enriched with contextual data like &quot;who&quot;, &quot;what&quot;, and &quot;where&quot;.
SRE teams and developers can then use it to browse through the recorded executions and check for errors or anomalies in execution that can signify either problems with deployments (services unavailabe) or even bugs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And this is where Debezium becomes part of the picture.
Data change events, as captured by Debezium from a database, and propagated via Kafka Connect and Apache Kafka to one more more downstream consumers are part of a data flow which is very valuable to have insight into.
How long does it take for change events to flow from source database to sink systems?
Where is the most time spent in the pipeline?
Are there any anomalies like spikes in end-to-end lags?
The integration of distributed tracing with Debezium can help to answer these questions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;opentracing&quot;&gt;OpenTracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are multiple solutions for distributed tracing, but as a starting point we have decided to follow and use the &lt;a href=&quot;https://opentracing.io/&quot;&gt;OpenTracing&lt;/a&gt; specification.
OpenTracing is an incubating project of &lt;a href=&quot;https://www.cncf.io/&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; which guarantees that the user will be free of any vendor lock-in by adhering to an open standard.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The OpenTracing project is in the process of being merged with OpenCensus to the improved &lt;a href=&quot;https://opentelemetry.io/&quot;&gt;OpenTelemetry&lt;/a&gt; standard.
Debezium uses OpenTracing at this point for alignment reasons with other projects (e.g. Quarkus),
but it will use and support OpenTelemetry in the future, too.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A distributed trace in OpenTracing consists of a set of spans.
Each span represents a logical unit of work executed.
The spans can form a tree when a larger part of the business transaction represented by one span can be compounded of multiple tasks represented by additional spans that have a parent-child relationship to the main span.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;OpenTracing is only the specification and the instrumentation API.
To use it you need to have an implementation, too.
While Debezium could be used any OpenTracing client implementation, our examples and documentation are based on the &lt;a href=&quot;https://www.jaegertracing.io/&quot;&gt;Jaeger&lt;/a&gt; distributed tracing platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jaeger consists of multiple components responsible for data collection and storage as well as a graphical user interface in form of a web application.
The Jaeger &lt;a href=&quot;https://www.jaegertracing.io/docs/1.21/getting-started/#all-in-one&quot;&gt;All-In-One&lt;/a&gt; container image will be used to simplify the deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;debezium_and_opentracing&quot;&gt;Debezium and OpenTracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Debezium integration with OpenTracing consists of three distinct components:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ActivateTracingSpan&lt;/code&gt; SMT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;EventDispatcher&lt;/code&gt; in the &lt;a href=&quot;/documentation/reference/integrations/outbox.html&quot;&gt;Debezium outbox extension&lt;/a&gt; for Quarkus applications&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;EventRouter&lt;/code&gt; &lt;a href=&quot;/documentation/reference/configuration/outbox-event-router.html&quot;&gt;SMT&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first one is intended for general use.
The latter two must be used hand-in-hand when a (Quarkus-based) service using the outbox pattern should be traced.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;outbox_distributed_tracing&quot;&gt;Outbox Distributed Tracing&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The biggest problem with tracing integration is keeping the trace across process boundaries so that all the related spans are recorded in the same trace to enable end-to-end tracing.
The OpenTracing specification provides a way how to export and import trace related metadata so the trace can be passed among different processes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the outbox extension we use this approach to export the metadata into a specific column in the outbox table, so that then the event router SMT can import them and resume the trace. In each of the steps executed one or more spans are created:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When an event arrives at &lt;code&gt;EventDispatcher&lt;/code&gt; a new span &lt;code&gt;outbox-write&lt;/code&gt; is created.
It is created as a child of a current active span (e.g. started by the invocation of an REST API of the current application), or as a root span if no parent span is available.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The span metadata is exported into a distinct field of the outbox event.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The outbox event is written to the outbox table.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Event Router SMT receives the event and imports the span metadata from the field&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two new spans are created&lt;/p&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;db-log-write&lt;/code&gt; with its start timestamp set to database write timestamp.
The fields from the &lt;code&gt;source&lt;/code&gt; block are added to the span as &lt;strong&gt;tags&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;debezium-read&lt;/code&gt; with its start time set to the processing timestamp.
Fields from the envelope are added to the span as &lt;strong&gt;tags&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Optionally, if OpenTracing integration is enabled at the Kafka producer level, a new span is created by the Kafka producer representing the write of the message to a Kafka topic with relevant metadata.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;demo&quot;&gt;Demo&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/debezium/debezium-examples/tree/master/outbox&quot;&gt;outbox example&lt;/a&gt; was extended with distributed tracing support to demonstrate the functionality.
This example contains two rudimentary microservices: an order service which exposes a REST API for placing purchase orders, and a shipment service which is notified by the order service about new purchase orders using the outbox pattern.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock note&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;i class=&quot;fa icon-note&quot; title=&quot;Note&quot;&gt;&lt;/i&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This demo uses the &lt;a href=&quot;https://strimzi.io/&quot;&gt;Strimzi&lt;/a&gt; container image for Kafka Connect, as it already contains baked-in integration of OpenTracing at Kafka producer level.&lt;/p&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To try it yourself you need to:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;check out the repository and switch to the &lt;code&gt;outbox&lt;/code&gt; directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;build the services&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;$ mvn clean install&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;deploy the application&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;export DEBEZIUM_VERSION=1.4
docker-compose up --build&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;register a Debezium connector to listen on the outbox table&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;$ http PUT http://localhost:8083/connectors/outbox-connector/config &amp;lt; register-postgres.json
HTTP/1.1 201 Created&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;execute multiple business requests&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;$ http POST http://localhost:8080/orders &amp;lt; resources/data/create-order-request.json
$ http PUT http://localhost:8080/orders/1/lines/2 &amp;lt; resources/data/cancel-order-line-request.json&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;check the &lt;a href=&quot;http://localhost:16686/&quot;&gt;Jaeger UI&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After all the steps above were completed you should see an introduction screen of the Jaeger UI:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-main.png&quot; class=&quot;responsive-image&quot; alt=&quot;Jaeger intro&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Filter on &lt;code&gt;order-service&lt;/code&gt; as a service and click on &lt;code&gt;Find Traces&lt;/code&gt;.
Two traces should be available:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-service.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Click on the &lt;code&gt;addOrder&lt;/code&gt; service.
A tree will open that displays how the initial request incoming via REST API was&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;written to the database by the outbox extension&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;read by Debezium and processed by outbox SMT&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;written to a Kafka topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;read from a Kafka topic by &lt;code&gt;shipment-service&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;processed in the different &lt;code&gt;shipment-service&lt;/code&gt; business methods&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-trace.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Click on the &lt;code&gt;db-log-write&lt;/code&gt; and &lt;code&gt;debezium-read&lt;/code&gt; spans.
The &lt;strong&gt;tags&lt;/strong&gt; of each of them contain extracted Debezium-related metadata like &lt;code&gt;operation&lt;/code&gt; or &lt;code&gt;source&lt;/code&gt; fields:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock centered-image&quot;&gt;
    &lt;img src=&quot;/assets/images/tracing-tutorial/tracing-debezium-details.png&quot; class=&quot;responsive-image&quot; alt=&quot;Service traces&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this blogpost, we have discussed what distributed tracing is and why it is beneficial to use it.
We have seen how the distributed tracing integration is done at the Debezium level to enable end-to-end tracing and tried a demo application together with Jaeger UI exploration.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While this example was focused on the specific use case of microservices data exchange via the outbox pattern,
Debezium integrates with distributed tracing also independently of this particular pattern.
By means of the &lt;code&gt;ActivateTracingSpan&lt;/code&gt; SMT, Debezium can produce spans representing the time of the change in the source database itself,
as well as the time of processing the event by the Debezium connector.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Support for distributed tracing is a new feature in Debezium 1.4 (originally added in Beta1) and will evolve and mature in subsequent releases.
Your feedback on this new functionality is highly welcomed!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Jiri Pechanec</name></author><category term="tracing" /><category term="jaeger" /><summary type="html">The current pattern in application development gravitates toward microservices and microservices architecture. While this approach gives the developer teams great flexibility in terms of independent deployments and development velocity, the drawback is at hand when you try to track a bug in production. Monolithic applications sit nicely at a single place so you can introspect the code flows and the application&amp;#8217;s runtime state. This is more challenging with microservice architectures, as a single business transaction can span across tens of services deployed in separate processes and compute nodes. You can rely on traditional methods like logging where you need to collect and correlate logs at a single place, so you can try to reconstruct the business transaction path. This is one of the tools in the box we can use, but it still can be crude and it will not provide all the necessary context. Distributed Tracing comes here to the rescue. Distributed Tracing Distributed tracing allows services to leave breadcrumbs during the execution with enough information to create an execution path of the business transaction enriched with contextual data like &quot;who&quot;, &quot;what&quot;, and &quot;where&quot;. SRE teams and developers can then use it to browse through the recorded executions and check for errors or anomalies in execution that can signify either problems with deployments (services unavailabe) or even bugs. And this is where Debezium becomes part of the picture. Data change events, as captured by Debezium from a database, and propagated via Kafka Connect and Apache Kafka to one more more downstream consumers are part of a data flow which is very valuable to have insight into. How long does it take for change events to flow from source database to sink systems? Where is the most time spent in the pipeline? Are there any anomalies like spikes in end-to-end lags? The integration of distributed tracing with Debezium can help to answer these questions. OpenTracing There are multiple solutions for distributed tracing, but as a starting point we have decided to follow and use the OpenTracing specification. OpenTracing is an incubating project of Cloud Native Computing Foundation which guarantees that the user will be free of any vendor lock-in by adhering to an open standard. The OpenTracing project is in the process of being merged with OpenCensus to the improved OpenTelemetry standard. Debezium uses OpenTracing at this point for alignment reasons with other projects (e.g. Quarkus), but it will use and support OpenTelemetry in the future, too. A distributed trace in OpenTracing consists of a set of spans. Each span represents a logical unit of work executed. The spans can form a tree when a larger part of the business transaction represented by one span can be compounded of multiple tasks represented by additional spans that have a parent-child relationship to the main span. OpenTracing is only the specification and the instrumentation API. To use it you need to have an implementation, too. While Debezium could be used any OpenTracing client implementation, our examples and documentation are based on the Jaeger distributed tracing platform. Jaeger consists of multiple components responsible for data collection and storage as well as a graphical user interface in form of a web application. The Jaeger All-In-One container image will be used to simplify the deployment. Debezium and OpenTracing The Debezium integration with OpenTracing consists of three distinct components: ActivateTracingSpan SMT EventDispatcher in the Debezium outbox extension for Quarkus applications EventRouter SMT The first one is intended for general use. The latter two must be used hand-in-hand when a (Quarkus-based) service using the outbox pattern should be traced. Outbox Distributed Tracing The biggest problem with tracing integration is keeping the trace across process boundaries so that all the related spans are recorded in the same trace to enable end-to-end tracing. The OpenTracing specification provides a way how to export and import trace related metadata so the trace can be passed among different processes. In the outbox extension we use this approach to export the metadata into a specific column in the outbox table, so that then the event router SMT can import them and resume the trace. In each of the steps executed one or more spans are created: When an event arrives at EventDispatcher a new span outbox-write is created. It is created as a child of a current active span (e.g. started by the invocation of an REST API of the current application), or as a root span if no parent span is available. The span metadata is exported into a distinct field of the outbox event. The outbox event is written to the outbox table. The Event Router SMT receives the event and imports the span metadata from the field Two new spans are created db-log-write with its start timestamp set to database write timestamp. The fields from the source block are added to the span as tags. debezium-read with its start time set to the processing timestamp. Fields from the envelope are added to the span as tags. Optionally, if OpenTracing integration is enabled at the Kafka producer level, a new span is created by the Kafka producer representing the write of the message to a Kafka topic with relevant metadata. Demo The outbox example was extended with distributed tracing support to demonstrate the functionality. This example contains two rudimentary microservices: an order service which exposes a REST API for placing purchase orders, and a shipment service which is notified by the order service about new purchase orders using the outbox pattern. This demo uses the Strimzi container image for Kafka Connect, as it already contains baked-in integration of OpenTracing at Kafka producer level. To try it yourself you need to: check out the repository and switch to the outbox directory build the services $ mvn clean install deploy the application export DEBEZIUM_VERSION=1.4 docker-compose up --build register a Debezium connector to listen on the outbox table $ http PUT http://localhost:8083/connectors/outbox-connector/config &amp;lt; register-postgres.json HTTP/1.1 201 Created execute multiple business requests $ http POST http://localhost:8080/orders &amp;lt; resources/data/create-order-request.json $ http PUT http://localhost:8080/orders/1/lines/2 &amp;lt; resources/data/cancel-order-line-request.json check the Jaeger UI After all the steps above were completed you should see an introduction screen of the Jaeger UI: Filter on order-service as a service and click on Find Traces. Two traces should be available: Click on the addOrder service. A tree will open that displays how the initial request incoming via REST API was written to the database by the outbox extension read by Debezium and processed by outbox SMT written to a Kafka topic read from a Kafka topic by shipment-service processed in the different shipment-service business methods Click on the db-log-write and debezium-read spans. The tags of each of them contain extracted Debezium-related metadata like operation or source fields: Conclusion In this blogpost, we have discussed what distributed tracing is and why it is beneficial to use it. We have seen how the distributed tracing integration is done at the Debezium level to enable end-to-end tracing and tried a demo application together with Jaeger UI exploration. While this example was focused on the specific use case of microservices data exchange via the outbox pattern, Debezium integrates with distributed tracing also independently of this particular pattern. By means of the ActivateTracingSpan SMT, Debezium can produce spans representing the time of the change in the source database itself, as well as the time of processing the event by the Debezium connector. Support for distributed tracing is a new feature in Debezium 1.4 (originally added in Beta1) and will evolve and mature in subsequent releases. Your feedback on this new functionality is highly welcomed!</summary></entry><entry><title type="html">Debezium 1.4.0.Beta1 Released</title><link href="https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Beta1 Released" /><published>2020-12-09T00:00:00+00:00</published><updated>2020-12-09T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released</id><content type="html" xml:base="https://debezium.io/blog/2020/12/09/debezium-1-4-beta1-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m pleased to announce the release of Debezium &lt;strong&gt;1.4.0.Beta1&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release includes support for distributed tracing,
lowercase table and schema naming for Db2,
specifying MySQL snapshot records as create or read operations,
and enhancements to Vitess for nullable and primary key columns.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Beta1%20ORDER%20BY%20issuetype%20DESC&quot;&gt;39 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;distributed_tracing&quot;&gt;Distributed Tracing&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In a nutshell, distributed tracing is a pattern used to profile and monitor applications to allow quick identification of failures or performance concerns.
Tracing works by having each component in a distributed process contribute a block of metadata called a &quot;span&quot;.
Each span contains unique details about that component&amp;#8217;s unit of work.
Typically a full distributed trace consists of a sequence of multiple spans.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Distributed tracing in Debezium is enabled by using the &lt;strong&gt;ActivateTracingSpan&lt;/strong&gt; SMT:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;&quot;transforms&quot;: &quot;tracing&quot;
&quot;transforms.tracing.type&quot;: &quot;io.debezium.transforms.tracing.ActivateTracingSpan&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The above configuration will lead to the emitted message header containing the tracing key/value pairs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A blog post discussing the distributed tracing support in depth, including end-to-end tracing for microservices data exchange via the outbox pattern, will follow up shortly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DDL parser: Allow stored procedure variables in LIMIT clause &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2692&quot;&gt;DBZ-2692&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wrong mysql command in openshift dpeloyment docs &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2746&quot;&gt;DBZ-2746&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;long running transaction will be abandoned and ignored &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2759&quot;&gt;DBZ-2759&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MS SQL Decimal with default value not matching the scale of the column definition cause exception &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2767&quot;&gt;DBZ-2767&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra Connector doesn&amp;#8217;t shut down completely &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2768&quot;&gt;DBZ-2768&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL Parser fails for BINARY collation shortcut &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2771&quot;&gt;DBZ-2771&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PostgresConnectorIT.shouldResumeStreamingFromSlotPositionForCustomSnapshot is failing for wal2json on CI &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2772&quot;&gt;DBZ-2772&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connector configuration property &quot;database.out.server.name&quot; is not relevant for Logminer implementation but cannot be omitted &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2801&quot;&gt;DBZ-2801&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CHARACTER VARYING mysql identifier for varchar is not supported in debezium &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2821&quot;&gt;DBZ-2821&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;try-with-resources should not be used when OkHttp Response object is returned &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2827&quot;&gt;DBZ-2827&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;EmbeddedEngine does not shutdown when commitOffsets is interrupted &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2830&quot;&gt;DBZ-2830&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rename user command parsing fails &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2743&quot;&gt;DBZ-2743&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/jeremy-l-ford&quot;&gt;Jeremy Ford&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hauntingEcho&quot;&gt;Matt Beary&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;,
&lt;a href=&quot;https://github.com/johnjmartin&quot;&gt;John Martin&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/seeekr&quot;&gt;Denis Andrejew&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m pleased to announce the release of Debezium 1.4.0.Beta1! This release includes support for distributed tracing, lowercase table and schema naming for Db2, specifying MySQL snapshot records as create or read operations, and enhancements to Vitess for nullable and primary key columns.</summary></entry><entry><title type="html">Debezium 1.4.0.Alpha2 Released</title><link href="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/" rel="alternate" type="text/html" title="Debezium 1.4.0.Alpha2 Released" /><published>2020-11-17T00:00:00+00:00</published><updated>2020-11-17T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/17/debezium-1-4-alpha2-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.4.0.Alpha2&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This second pass of the 1.4 release line provides a few useful new features:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;New API hook for the PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; interface&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Field renaming using &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT&amp;#8217;s &lt;code&gt;add.fields&lt;/code&gt; and &lt;code&gt;add.headers&lt;/code&gt; configurations&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Overall, the community fixed &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.4.0.Alpha2%20ORDER%20BY%20issuetype%20DESC&quot;&gt;37 issues&lt;/a&gt; for this release.
Let&amp;#8217;s take a closer look at some of the highlights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;postgresql_snapshotter_completion_hook&quot;&gt;PostgreSQL Snapshotter completion hook&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The PostgreSQL &lt;code&gt;Snapshotter&lt;/code&gt; API is a contract that allows for the customization of the snapshot process.
This API was introduced in 0.9.3.Final and has continued to evolve in the releases since.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A new backward compatible completion hook has been added:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;void snapshotCompleted()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This new hook is called by the snapshot process when the snapshot has concluded,
allowing implementations to clean-up any resources it may have allocated prior streaming changes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;extractnewrecordstate_smt_field_renaming_support&quot;&gt;ExtractNewRecordState SMT field renaming support&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the features of the &lt;code&gt;ExtractNewRecordState&lt;/code&gt; SMT is that the transformation can retain parts of the original message in the transformed message&amp;#8217;s header or payload.
This release extends this feature to allow specifying a new name to be used for the field when added to the message header or payload.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For example, to add the source database&amp;#8217;s event timestamp to the message header using the new renaming feature, the SMT configuration would be:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;CodeRay highlight&quot;&gt;&lt;code&gt;transforms=unwrap
transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
transforms.unwrap.add.headers=source.ts_ms:timestamp&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The format of the &lt;code&gt;add.headers&lt;/code&gt; and &lt;code&gt;add.fields&lt;/code&gt; configuration options have been improved to support a comma-separated list of fields with the syntax &lt;code&gt;&amp;lt;OLD_FIELD&amp;gt;[:NEW_FIELD]&lt;/code&gt;.
The above emitted message&amp;#8217;s headers would now contain &lt;code&gt;__timestamp&lt;/code&gt; rather than the default &lt;code&gt;__source.ts_ms&lt;/code&gt; field.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This syntax improvement remains backward compatible.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;bugfixes&quot;&gt;Bugfixes&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Also a number of bugs were fixed, e.g.:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Oracle throw &quot;no snapshot found based on specified time&quot; when running flashback query &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exception when PK definition precedes column definition &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2580&quot;&gt;DBZ-2580&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Patroni can&amp;#8217;t stop PostgreSQL when Debezium is streaming &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2617&quot;&gt;DBZ-2617&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChangeRecord informations don&amp;#8217;t connect with the TableSchema &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2679&quot;&gt;DBZ-2679&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL connector fails on a zero date &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2682&quot;&gt;DBZ-2682&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oracle LogMiner doesn&amp;#8217;t support partition tables &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2683&quot;&gt;DBZ-2683&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DB2 doesn&amp;#8217;t start reliably in OCP  &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2693&quot;&gt;DBZ-2693&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dropped columns cause NPE in SqlServerConnector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2716&quot;&gt;DBZ-2716&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timestamp default value in 'yyyy-mm-dd' format fails MySQL connector &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2726&quot;&gt;DBZ-2726&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connection timeout on write should retry &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2727&quot;&gt;DBZ-2727&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No viable alternative at input error on &quot;min&quot; column &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQLServer CI error in SqlServerConnectorIT.whenCaptureInstanceExcludesColumnsAndColumnsRenamedExpectNoErrors:1473 &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2747&quot;&gt;DBZ-2747&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;debezium-connector-db2: DB2 SQL Error: SQLCODE=-206 on DB2 for z/OS &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2755&quot;&gt;DBZ-2755&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;no viable alternative at input 'alter table &lt;code&gt;order&lt;/code&gt; drop CONSTRAINT' &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2760&quot;&gt;DBZ-2760&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tests are failing on macos &lt;a href=&quot;https://issues.jboss.org/browse/DBZ-2762&quot;&gt;DBZ-2762&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to all the contributors from the community who worked on this release:
&lt;a href=&quot;https://github.com/Iskuskov&quot;&gt;Alexander Iskuskov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/alisator&quot;&gt;Alisa Houskova&lt;/a&gt;,
&lt;a href=&quot;https://github.com/ani-sha&quot;&gt;Anisha Mohanty&lt;/a&gt;,
&lt;a href=&quot;https://github.com/AndreyIg&quot;&gt;Andrey Ignatenko&lt;/a&gt;,
&lt;a href=&quot;https://github.com/creactiviti&quot;&gt;Arik Cohen&lt;/a&gt;,
&lt;a href=&quot;https://github.com/bduisenov&quot;&gt;Babur Duisenov&lt;/a&gt;,
&lt;a href=&quot;https://github.com/grantcooksey&quot;&gt;Grant Cooksey&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rgannu&quot;&gt;Ganesh Ramasubramanian&lt;/a&gt;,
&lt;a href=&quot;https://github.com/vanhoale&quot;&gt;Hoa Le&lt;/a&gt;,
&lt;a href=&quot;https://github.com/keweishang&quot;&gt;Kewei Shang&lt;/a&gt;,
&lt;a href=&quot;https://github.com/mans2singh&quot;&gt;Mans Singh&lt;/a&gt;,
&lt;a href=&quot;https://github.com/hussain-k1&quot;&gt;Mohamed Pudukulathan&lt;/a&gt;,
&lt;a href=&quot;https://github.com/zrlurb&quot;&gt;Peter Urbanetz&lt;/a&gt;,
&lt;a href=&quot;https://github.com/rareddy&quot;&gt;Ramesh Reddy&lt;/a&gt;,
&lt;a href=&quot;https://github.com/morozov&quot;&gt;Sergei Morozov&lt;/a&gt;, and
&lt;a href=&quot;https://github.com/ramanenka&quot;&gt;Vadzim Ramanenka&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="mongodb" /><category term="sqlserver" /><category term="cassandra" /><category term="db2" /><category term="oracle" /><category term="vitess" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.4.0.Alpha2! This second pass of the 1.4 release line provides a few useful new features: New API hook for the PostgreSQL Snapshotter interface Field renaming using ExtractNewRecordState SMT&amp;#8217;s add.fields and add.headers configurations</summary></entry><entry><title type="html">Debezium 1.3.1.Final Released</title><link href="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/" rel="alternate" type="text/html" title="Debezium 1.3.1.Final Released" /><published>2020-11-12T00:00:00+00:00</published><updated>2020-11-12T00:00:00+00:00</updated><id>https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released</id><content type="html" xml:base="https://debezium.io/blog/2020/11/12/debezium-1-3-1-final-released/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I&amp;#8217;m excited to announce the release of Debezium &lt;strong&gt;1.3.1.Final&lt;/strong&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This release primarily focuses on bugs that were reported after the 1.3 release.
Most importantly, the following bugs were fixed related to the &lt;a href=&quot;/docs/connectors/oracle&quot;&gt;Debezium connector for Oracle&lt;/a&gt; LogMiner adapter thanks to the continued feedback by the Debezium community.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SQLExceptions thrown when using Oracle LogMiner (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2624&quot;&gt;DBZ-2624&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LogMiner mining session stopped due to WorkerTask killed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2629&quot;&gt;DBZ-2629&lt;/a&gt;)
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In addition, there were other bugs identified and fixed in this release, including:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;[MongoDB] Sanitization of field names not applied to nested struct fields (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2680&quot;&gt;DBZ-2680&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] MariaDB nextval function is not supported by grammar (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2671&quot;&gt;DBZ-2671&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MSSQL] Hide stack-trace when default value cannot be parsed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2642&quot;&gt;DBZ-2642&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Upgrade JDBC driver to 8.0.19 (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2626&quot;&gt;DBZ-2626&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] ANTLR parser fails to interpret &lt;code&gt;BLOB(size)&lt;/code&gt; types (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2641&quot;&gt;DBZ-2641&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Should allow non-ascii character in SQL (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2670&quot;&gt;DBZ-2670&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] Connector fails if non-existing view with same name as table is dropped (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2688&quot;&gt;DBZ-2688&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[MySQL] No viable alternative at input error when column uses aggregate function names (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2738&quot;&gt;DBZ-2738&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Oracle] No snapshot found based on specified time (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-1446&quot;&gt;DBZ-1446&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[PostgreSQL] WAL logs are not properly flushed (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2653&quot;&gt;DBZ-2653&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[Server] Event Hubs plugin support (&lt;a href=&quot;https://issues.redhat.com/browse/DBZ-2660&quot;&gt;DBZ-2660&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Altogether, &lt;a href=&quot;https://issues.redhat.com/issues/?jql=project%20%3D%20DBZ%20AND%20fixVersion%20%3D%201.3.1.Final&quot;&gt;14 issues&lt;/a&gt; were resolved in this release.
Please refer to the &lt;a href=&quot;/releases/1.3/release-notes/#release-1.3.1-final&quot;&gt;release notes&lt;/a&gt; to learn more about all fixed bugs, update procedures etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;A big thank you to everyone who helped test and identify these bugs.
The team appreciates the invaluable feedback the community continually provides!&lt;/p&gt;
&lt;/div&gt;</content><author><name>Chris Cranford</name></author><category term="releases" /><category term="mysql" /><category term="postgres" /><category term="sqlserver" /><category term="cassandra" /><category term="oracle" /><category term="db2" /><category term="vitess" /><category term="outbox" /><summary type="html">I&amp;#8217;m excited to announce the release of Debezium 1.3.1.Final! This release primarily focuses on bugs that were reported after the 1.3 release. Most importantly, the following bugs were fixed related to the Debezium connector for Oracle LogMiner adapter thanks to the continued feedback by the Debezium community. SQLExceptions thrown when using Oracle LogMiner (DBZ-2624) LogMiner mining session stopped due to WorkerTask killed (DBZ-2629)</summary></entry><entry><title type="html">Streaming Vitess at Bolt</title><link href="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/" rel="alternate" type="text/html" title="Streaming Vitess at Bolt" /><published>2020-11-04T16:19:59+00:00</published><updated>2020-11-04T16:19:59+00:00</updated><id>https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt</id><content type="html" xml:base="https://debezium.io/blog/2020/11/04/streaming-vitess-at-bolt/">&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&quot;https://medium.com/bolt-labs/streaming-vitess-at-bolt-f8ea93211c3f&quot;&gt;Bolt Labs Engineering blog&lt;/a&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Traditionally, MySQL has been used to power most of the backend services at &lt;a href=&quot;https://bolt.eu/en/&quot;&gt;Bolt&lt;/a&gt;. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Once data is persisted to the database, we use the &lt;a href=&quot;https://debezium.io/documentation/reference/connectors/mysql.html&quot;&gt;Debezium MySQL Connector&lt;/a&gt; to &lt;a href=&quot;https://www.confluent.io/blog/how-bolt-adopted-cdc-with-confluent-for-real-time-data-and-analytics/&quot;&gt;capture data change events&lt;/a&gt; and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.
&lt;!-- more --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess_at_bolt&quot;&gt;Vitess at Bolt&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Bolt has grown considerably over the past few years, and so did the volume of data written to MySQL. Manual database sharding has become quite an expensive and long-lasting process prone to errors. So we started to evaluate more scalable databases, one of which is &lt;a href=&quot;https://vitess.io/&quot;&gt;Vitess&lt;/a&gt;. Vitess is an open-source database clustering system that is based on MySQL and provides horizontal scalability for it. Originated and battle-tested at YouTube, it was later open-sourced and is used by companies like Slack, Github, JD.com to power their backend storage. It combines important MySQL features with the scalability of a NoSQL database.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the most important features that Vitess provides is its built-in sharding. It allows the database to grow horizontally by adding new shards in a way that is transparent to back-end application logic. To your application, Vitess appears like a giant single database, but in fact data is partitioned into multiple physical shards behind the scenes. For any table, an arbitrary column can be chosen as the sharding key, and all inserts and updates will be seamlessly directed to a proper shard by Vitess itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;em&gt;Figure 1&lt;/em&gt; below illustrates how back-end services interact with Vitess. At a high level, services connect to the stateless VTGate instances through a load balancer. Each VTGate has the Vitess cluster’s topology cached in its memory and redirects queries to the correct shards and the correct VTTablet (and its underlying MySQL instance) within the shards. More on VTTablet is written below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_architecture.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 1. Vitess architecture. Reference: &lt;a href=&quot;https://www.planetscale.com/vitess&quot; class=&quot;bare&quot;&gt;https://www.planetscale.com/vitess&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Other useful features provided by Vitess are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Failover (a.k.a. Reparenting) is easy and transparent for clients. Clients only talk to a VTGate who takes care of failover and service discovery of the new primary transparently.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It automatically rewrites “problematic” queries that could potentially cause database performance degradation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has a caching mechanism that prevents duplicate queries to reach the underlying MySQL database simultaneously. Only one query will reach the database and its result will be cached and returned to answer duplicate queries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has its connection pool and eliminates the high-memory overhead of MySQL connections. As a result, it can easily handle thousands of connections at the same time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connection timeout and transaction timeout can be configured.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has minimal downtime when doing &lt;a href=&quot;https://vitess.io/docs/user-guides/configuration-advanced/resharding/&quot;&gt;resharding&lt;/a&gt; operations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Its VStream feature can be used by downstream CDC applications to read change events from Vitess.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;streaming_vitess_options&quot;&gt;Streaming Vitess Options&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The ability to capture data changes and publish them to Apache Kafka was one of the requirements for adopting Vitess at Bolt. There were several different options we’ve considered.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option_1_using_debezium_mysql_connector&quot;&gt;Option 1: Using Debezium MySQL Connector&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Applications connect to Vitess VTGate to send queries. VTGate supports the MySQL protocol and has a SQL parser. You can use any MySQL client (e.g. JDBC) to connect to VTGate, which redirects your query to the correct shard and returns the result to your client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, VTGate is not equal to a MySQL instance, it is rather a stateless proxy to various MySQL instances. For the MySQL connector to receive change events, the Debezium MySQL connector needs to connect to a real MySQL instance. To make it more obvious, VTGate also has some known &lt;a href=&quot;https://vitess.io/docs/reference/compatibility/mysql-compatibility/&quot;&gt;compatibility&lt;/a&gt; issues, which makes connecting to VTGate different from MySQL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another option is to use the Debezium MySQL Connector to connect directly to the underlying MySQL instances of different shards. It has its advantages and disadvantages.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One advantage is that for an unsharded keyspace (Vitess&amp;#8217;s terminology for a database), the MySQL Connector can continue to work correctly and we don&amp;#8217;t need to include additional logic or specific implementation. It should just work fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;One of the biggest disadvantages is that resharding operations would become more complex. For example, the GTID of the original MySQL instance would change when resharded, and the MySQL connector depends on the GTID to work correctly. We also believe that having the MySQL connector connected directly to each underlying MySQL instance defies the purpose of Vitess&amp;#8217;s operational simplicity as a new connector has to be added (or removed) each time resharding is done. Not to mention that such operation would lead to data duplication inside Kafka brokers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option_2_using_jdbc_source_connector&quot;&gt;Option 2: Using JDBC Source Connector&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We&amp;#8217;ve also considered using the &lt;a href=&quot;https://docs.confluent.io/current/connect/kafka-connect-jdbc/source-connector/index.html&quot;&gt;JDBC Source Connector&lt;/a&gt;. It allows sourcing data from any relational databases that support the JDBC driver into Kafka. Therefore, it is compatible with Vitess VTGate. It has its advantages and disadvantages as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is compatible with VTGate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It handles Vitess resharding operation better. During resharding operation, reads are simply automatically redirected (by VTGate) to the target shards. It won&amp;#8217;t generate any duplicates or lose any data.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Disadvantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is poll-based, meaning that the connector polls the database for new change events on a defined interval (typically every few seconds). This means that we would have a much higher latency, compared to the Debezium MySQL Connector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Its offsets are managed by either the table&amp;#8217;s incremental primary key or one of the table&amp;#8217;s timestamp columns. If we use the timestamp column for offset, we&amp;#8217;d have to create a secondary-index of the timestamp column for each table. This adds more constraints on our backend services. If we use the incremental primary key, we would miss the change events for row-updates because the primary key is simply not updated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The topic name created by the JDBC connector doesn&amp;#8217;t include the table&amp;#8217;s schema name. Using the &lt;code&gt;topic.prefix&lt;/code&gt; connector configuration would mean that we&amp;#8217;ll have one connector per schema. At Bolt, we have a large number of schemas, which means we would need to create a large number of JDBC Source Connectors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At Bolt, our downstream applications are already set up to use Debezium&amp;#8217;s data formats and topic naming conventions, e.g. we&amp;#8217;d need to change our downstream application&amp;#8217;s decoding logic to the new data formats.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Row deletes are not captured.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;option_3_using_vstream_grpc&quot;&gt;Option 3: Using VStream gRPC&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VTGate exposes a gRPC service called VStream. It is a server-side streaming service. Any gRPC client can subscribe to the &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;VStream&lt;/a&gt; service to get a continuous stream of change events from the underlying MySQL instances. The change events that VStream emits have similar information to the MySQL binary logs of the underlying MySQL instances. A single VStream can even subscribe to multiple shards for a given keyspace, making it quite a convenient API to build CDC tools.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Behind the scene, as shown in &lt;em&gt;Figure 2&lt;/em&gt;, VStream reads change events from multiple &lt;a href=&quot;https://vitess.io/docs/reference/programs/vttablet/&quot;&gt;VTTablets&lt;/a&gt;, one VTTablet per shard. Therefore, it doesn’t send duplicates from multiple VTTablets for a given shard. Each VTTablet is a proxy to its MySQL instance. A typical topology would include one master VTTablet and its corresponding MySQL instance, and multiple replica VTTablets, each of which is the proxy of its own replica MySQL instance. A VTTablet gets change events from its underlying MySQL instance and sends the change events back to VTGate, which in turn sends the change events back to VStream’s gRPC client.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;When subscribing to the VStream service, the client can specify a VGTID and &lt;a href=&quot;https://vitess.io/docs/concepts/tablet/#tablet-types&quot;&gt;Tablet Type&lt;/a&gt; (e.g. &lt;code&gt;MASTER&lt;/code&gt;, &lt;code&gt;REPLICA&lt;/code&gt;). The VGTID tells the position from which VStream starts to send change events. Essentially, VGTID includes a list of (keyspace, shard, shard GTID) tuples. The Tablet Type tells which MySQL instance (primary or replica) in each shard do we read change events from.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vstream.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 2. VStream architecture. Reference: &lt;a href=&quot;https://vitess.io/docs/concepts/vstream&quot; class=&quot;bare&quot;&gt;https://vitess.io/docs/concepts/vstream&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Some advantages of using VStream gRPC are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is a simple way to receive change events from Vitess. It is also recommended in Vitess’s &lt;a href=&quot;https://vitess.io/docs/concepts/vstream/&quot;&gt;documentation&lt;/a&gt; to use VStream to build CDC processes downstream.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VTGate hides the complexity of connecting to various source MySQL instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It has low latency since change events are streamed to the client as soon as they happen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The change events include not only inserts and updates, but also deletes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Probably one of the biggest advantages is that the change events contain the schema of each table. So you don’t have to worry about fetching each table’s schema in advance (by,  for example, parsing DDLs or querying the table’s definition).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The change events have VGTID included, which the CDC process can store and use as the offset from where to restart the CDC process next time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also importantly, VStream is designed to work well with Vitess operations such as &lt;a href=&quot;https://vitess.io/docs/user-guides/resharding/&quot;&gt;Resharding&lt;/a&gt; and &lt;a href=&quot;https://vitess.io/docs/user-guides/move-tables/&quot;&gt;Moving Tables&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There are also some disadvantages:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Although it includes table schemas, some important information is still missing. For example, the &lt;code&gt;Enum&lt;/code&gt; and &lt;code&gt;Set&lt;/code&gt; column types don’t provide all the allowed values yet. This should be fixed in the next major release (Vitess 9) though.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since VStream is a gRPC service, we cannot use the Debezium MySQL Connector out-of-the-box. However, it is quite straightforward to implement the gRPC client in other languages.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;All things considered, we’ve decided to use VStream gRPC to capture change events from Vitess and implement our Vitess Connector based on all the best practices of Debezium.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;vitess_connector_deep_dive_and_open_source&quot;&gt;Vitess Connector Deep Dive and Open Source&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After we’ve decided to implement our Vitess Connector, we started looking into the implementation details of various Debezium source connectors (MySQL, Postgres, SQLServer), to borrow some ideas. Almost all of them are implemented using a common Connector development framework. So it was clear we should develop the Vitess connector on top of it. Given we are very active users of the MySql Connector and we benefit from it being open-sourced, as it allows us to contribute to it things we were missing ourselves. So we decided we want to give back to community and open-source the Vitess source connector code-base under the Debezium umbrella. Please feel free to learn more at &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Debezium Connector Vitess&lt;/a&gt;. We welcome and value any contributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;At a high level, as you can see below, connector instances are created in Kafka Connect workers. At the time of writing, you have two options to configure the connector to read from Vitess:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Option 1 (recommended):&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As shown in &lt;em&gt;Figure 3&lt;/em&gt;, each connector captures change events from all shards in a specific keyspace. If the keyspace is not sharded, the connector can still capture change events from the only shard in the keyspace. When it’s the first time that the connector starts, it reads from the current VGTID position of all shards in the keyspace. Because it subscribes to all shards, it continuously captures change events from all shards and sends them to Kafka. It automatically supports the Vitess Reshard operation, there is no data loss, nor duplication.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_multi_shards.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 3. Each connector subscribes to all shards of a specific keyspace&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Option 2:&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As shown in &lt;em&gt;Figure 4&lt;/em&gt;, each connector instance captures change events from a specific keyspace/shard pair. The connector instance gets the initial (the current) VGTID  position of the keyspace/shard pair from VTCtld gRPC, which is another Vitess component. Each connector instance, independently, uses the VGTID it gets to subscribe to VStream gRPC and continuously capture change events from VStream and sends them to Kafka. To support the Vitess Reshard operation, you would need more manual operations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_single_shard.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 4. Each connector subscribes to one shard of a specific keyspace&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Internally, each connector task uses a gRPC thread to constantly receive change events from VStream and puts the events into an internal blocking queue. The connector task thread polls events out of the queue and sends them to Kafka, as can be seen in &lt;em&gt;Figure 5&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;exampleblock centered-image responsive-image&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/vitess/vitess_connector_internal.png&quot; style=&quot;max-width:100%;&quot; class=&quot;responsive-image&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Figure 5. How each connector task works internally&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;replication_challenges&quot;&gt;Replication Challenges&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;While we were implementing the Vitess Connector and digging deeper into Vitess, we’ve also realized a few challenges.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;vitess_reshard&quot;&gt;Vitess Reshard&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The Vitess connector supports the Vitess Reshard operation when the connector is configured to subscribe to all shards of a given keyspace. VStream sends a VGTID that contains the shard GTID for all shards. Vitess Resharding is transparent to users. Once it’s completed, Vitess will send the VGTID of the new shards. Therefore, the connector will use the new VGTID after reshard. However, you need to make sure that the connector is up and running when the reshard operation takes place. Especially please check that the offset topic of the connector has the new VGTID before deleting the old shards. This is because in case the old shards are deleted, VStream will not be able to recognize the VGTID from the old shards.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;If you decide to subscribe to one shard per connector, the connector does not provide out-of-the-box support for Vitess resharding. One manual workaround to support resharding is creating one new connector per target shard. For example, one new connector for the &lt;code&gt;commerce/-80&lt;/code&gt; shard, and another new connector for the &lt;code&gt;commerce/80-&lt;/code&gt; shard. Bear in mind that because they’re new connectors, by default, new topics will be created, however, you could use the &lt;a href=&quot;https://debezium.io/documentation/reference/configuration/topic-routing.html&quot;&gt;Debezium logical topic router&lt;/a&gt; to route the records to the same Kafka topics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;offset_management&quot;&gt;Offset Management&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VStream includes a VGTID event in its response. We save the VGTID as the offset in the Kafka offset topic, so when the connector restarts, we can start from the saved VGTID. However, in rare cases when a transaction includes a huge amount of rows, VStream batches the change events into multiple responses, and only the last response has the VGTID. In such cases, we don’t have the VGTID for every change event we receive. We have a few options to solve this particular issue:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can buffer all the change events in memory and wait for the last response that contains the VGTID to arrive. So all events will have the correct VGTID associated with them. A few disadvantages are that we’ll have higher latency before events are sent to Kafka. Also, memory usage could potentially increase quite a lot due to buffering. Buffering also adds complexity to the logic. We also have no control over the number of events VStream sends to us.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can use the latest VGTID we have, which is the VGTID from the previous VStream response. If the connector fails and restarts when processing such a big transaction, it’ll restart from the VGTID of the previous VStream response, thus reprocessing some events. Therefore, it has at-least-once event delivery semantics and it expects the downstream to be idempotent. Since most transactions are not big enough, most VStream responses will have VGTID in the response, so the chance of having duplicates is low. In the end, we chose this approach for its at-least-once delivery guarantee and its design simplicity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;schema_management&quot;&gt;Schema Management&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;VStream’s response also includes a &lt;code&gt;FIELD&lt;/code&gt; event. It’s a special event that contains the schemas of the tables of which the rows are affected. For example, let&amp;#8217;s assume we have 2 tables, &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt;. If we insert a few rows into table &lt;code&gt;A&lt;/code&gt;, the &lt;code&gt;FIELD&lt;/code&gt; event will only contain table &lt;code&gt;A&lt;/code&gt;’s schema. The VStream is smart enough to only include the &lt;code&gt;FIELD&lt;/code&gt; event whenever necessary. For example, when a VStream client reconnects, or when a table’s schema is changed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The older version of VStream includes only the column type (e.g. &lt;code&gt;Integer&lt;/code&gt;, &lt;code&gt;Varchar&lt;/code&gt;), no additional information such as whether the column is the primary key, whether the column has a default value, &lt;code&gt;Decimal&lt;/code&gt; type’s scale and precision, &lt;code&gt;Enum&lt;/code&gt; type’s allowed values, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The newer version (Vitess 8) of VStream starts to include more information on each column. This will help the connector to deserialize more accurately certain types and have a more precise schema in the change events sent to Kafka.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;future_development_work&quot;&gt;Future Development Work&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We can use VStream&amp;#8217;s API to start streaming from the latest VGTID position, instead of getting the initial VGTID position from VTCtld gRPC. Doing so would eliminate the dependency from VTCtld.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We don’t support automatically extracting the primary keys from the change events yet. Currently, by default, all change events sent to Kafka have &lt;code&gt;null&lt;/code&gt; as the key, unless the &lt;code&gt;message.key.columns&lt;/code&gt; connector configuration is specified. Vitess recently added flags of each column in the VStream FIELD event, which allows us to implement this feature soon.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add support for initial snapshots to capture all existing data before streaming changes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;MySQL has been used to power most of our backend services at Bolt. Due to the considerable growth of the volume of data and operational complexity, Bolt started to evaluate Vitess for its scalability and its built-in features such as resharding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;To capture data changes from Vitess, as what we’ve been doing with Debezium MySQL Connector, we’ve considered a few options. In the end, we have implemented our own Vitess Connector based on the common Debezium connector framework. While implementing the Vitess connector, we’ve encountered a few challenges. For example, support for the Vitess reshard operation, offset management, and schema management. We reasoned about ways to address the challenges and what we worked out as solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We’ve also received quite some interest from multiple communities in this project and we’ve decided to open-source &lt;a href=&quot;https://github.com/debezium/debezium-connector-vitess/&quot;&gt;Vitess Connector&lt;/a&gt; under the Debezium umbrella. Please feel free to learn more, and we welcome and value any contributions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>keweishang, rgibaiev</name></author><category term="vitess" /><summary type="html">This post originally appeared on the Bolt Labs Engineering blog. Traditionally, MySQL has been used to power most of the backend services at Bolt. We&amp;#8217;ve designed our schemas in a way that they&amp;#8217;re sharded into different MySQL clusters. Each MySQL cluster contains a subset of data and consists of one primary and multiple replication nodes. Once data is persisted to the database, we use the Debezium MySQL Connector to capture data change events and send them to Kafka. This gives us an easy and reliable way to communicate changes between back-end microservices.</summary></entry></feed>